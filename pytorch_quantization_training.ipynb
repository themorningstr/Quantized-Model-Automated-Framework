{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharp-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f18186ab3d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from collections import OrderedDict\n",
    "import torch.quantization\n",
    "import catalyst as c\n",
    "from sklearn.metrics import f1_score\n",
    "from catalyst.contrib.losses import FocalLossMultiClass\n",
    "import copy\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "from coremltools.optimize.torch.quantization import LinearQuantizer, LinearQuantizerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "frequent-notion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pressing-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0b1\n"
     ]
    }
   ],
   "source": [
    "print(ct.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7d5214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.04\n"
     ]
    }
   ],
   "source": [
    "print(c.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dynamic-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '/opt/infilect/dev/dataset/resize'\n",
    "# train_directory = data_directory + '/train'\n",
    "# # validation_directory = data_directory + '/valid'\n",
    "# test_directory = data_directory + '/test'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0a7103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Callable, Dict, List\n",
    "\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "\n",
    "def threadSkeleton(myId: str, workerFunc: Callable, recvQueue: Queue, \n",
    "                   sendQueue: Queue, **kwargs):\n",
    "\n",
    "    print(F\" Thread {myId} -> Starting...\")\n",
    "    objProcessed = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        try: thisJob = recvQueue.get(block=True, timeout=5)\n",
    "        except: thisJob = None\n",
    "\n",
    "        if thisJob is None: continue\n",
    "        if thisJob == \"END\": break\n",
    "        thisJob = workerFunc(thisJob, **kwargs)\n",
    "\n",
    "        if not thisJob is None: sendQueue.put(thisJob)\n",
    "        objProcessed += 1\n",
    "\n",
    "    print(F\" Thread {myId} -> Ending. Samples processed {objProcessed}\")\n",
    "\n",
    "    pass\n",
    "\n",
    "class ThreadHandler:\n",
    "\n",
    "    def __init__(self, nProcesses: int=12) -> None:\n",
    "\n",
    "        self.nProcesses = nProcesses\n",
    "\n",
    "        self.processQueue = [Queue() for __ in range(nProcesses)]\n",
    "        self.resultsQueue = Queue()\n",
    "\n",
    "        self.currProcessIndex = 0\n",
    "        self.threadList: List[Thread] = []\n",
    "        pass\n",
    "    \n",
    "    def startThreads(self, workerFunc: Callable, **kwargs):\n",
    "        for i in range(self.nProcesses):\n",
    "            tThread = Thread(target=threadSkeleton, args=[i, workerFunc, self.processQueue[i], \n",
    "                                                            self.resultsQueue], kwargs=kwargs)\n",
    "            tThread.start()\n",
    "            self.threadList.append(tThread)\n",
    "        pass\n",
    "    \n",
    "    def putJob(self, thisJob: Dict):\n",
    "        self.processQueue[self.currProcessIndex].put(thisJob)\n",
    "        self.currProcessIndex += 1\n",
    "        if self.currProcessIndex == self.nProcesses: self.currProcessIndex = 0\n",
    "        pass\n",
    "\n",
    "    def endThreads(self,):\n",
    "        for q in self.processQueue: q.put(\"END\")\n",
    "        for t in self.threadList: t.join()\n",
    "        pass\n",
    "\n",
    "    def getResults(self,) -> List[Dict]: return list(self.resultsQueue.queue)\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2053c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:229: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Callable, Dict, Tuple, Set, List\n",
    "import os\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BalancedLoader(Dataset):\n",
    "\n",
    "    def __init__(self, rootPath: str, augObject: Callable=None, validLbls: Set[str]=set(), \n",
    "                cacheImgs: bool=True, minSampPerClass: int=-1, maxSampPerClass: int=-1, \n",
    "                nProcesses: int=15) -> None:\n",
    "\n",
    "        self.rootPath = rootPath\n",
    "        self.augObject = augObject\n",
    "        self.validLbls = set(validLbls)\n",
    "        self.cacheImgs = cacheImgs\n",
    "        self.minSampPerClass = minSampPerClass\n",
    "        self.maxSampPerClass = maxSampPerClass\n",
    "        self.nProcesses = nProcesses\n",
    "\n",
    "        if cacheImgs: \n",
    "            self.dataDict, self.filesPerClass, self.nFiles = self.__cacheImages()\n",
    "        else: \n",
    "            self.dataDict, self.filesPerClass, self.nFiles = self.__getFileNames()\n",
    "        \n",
    "        self.allClasses = sorted(list(self.filesPerClass.keys()))\n",
    "        self.label2Idx, self.idx2Label = self.__tagLabelMap()\n",
    "        self.nClasses = len(self.allClasses)\n",
    "\n",
    "        self.__clsItr, self.__balLen = 0, 0\n",
    "        self.balIdxs = self.getBalancedIndices()\n",
    "        pass\n",
    "    \n",
    "    def __len__(self,) -> int: return self.__balLen\n",
    "\n",
    "    def __tagLabelMap(self,):\n",
    "        \n",
    "        if \"notImportant\" in self.allClasses:\n",
    "            excClass = [self.allClasses.pop(self.allClasses.index(\"notImportant\"))]\n",
    "            self.allClasses = excClass + self.allClasses\n",
    "\n",
    "        label2Idx, idx2Label = {}, {}\n",
    "        for i in range(len(self.allClasses)): \n",
    "            label2Idx[self.allClasses[i]], idx2Label[i] = i, self.allClasses[i]\n",
    "        return label2Idx, idx2Label\n",
    "\n",
    "    def __getFileNames(self,) -> Tuple[Dict, int]:\n",
    "\n",
    "        dataDict, filesPerClass, totalFiles = {}, {}, 0\n",
    "        if len(self.validLbls) == 0: self.validLbls = set(os.listdir(self.rootPath))\n",
    "\n",
    "        for c in os.listdir(self.rootPath):\n",
    "            thisFiles = pd.Series(os.listdir(F\"{self.rootPath}/{c}\"))\n",
    "            if self.minSampPerClass != -1 and len(thisFiles) < self.minSampPerClass: continue\n",
    "            \n",
    "            mCls = c if c in self.validLbls else \"notImportant\"\n",
    "            dataDict[mCls] = dataDict.get(mCls, [])\n",
    "            filesPerClass[mCls] = filesPerClass.get(mCls, 0)\n",
    "\n",
    "            dataDict[mCls] += ( F\"{self.rootPath}/{c}/\" + thisFiles ).tolist()\n",
    "            filesPerClass[mCls] = len(dataDict[mCls])\n",
    "            totalFiles += len(thisFiles)\n",
    "\n",
    "        return dataDict, filesPerClass, totalFiles\n",
    "    \n",
    "    def __cacheImages(self,) -> Dict:\n",
    "        \n",
    "        print(\" Caching Images....\")\n",
    "        dataDict, filesPerClass, nFiles = self.__getFileNames()\n",
    "        outDict = {k: [] for k in dataDict.keys()}\n",
    "\n",
    "        def __loadImage(readImg: Dict) -> None:\n",
    "            imgCls, imgFile = readImg[\"imgCls\"], readImg[\"imgFile\"]\n",
    "            tImg = np.asarray(Image.open(imgFile)).copy()\n",
    "            outDict[imgCls].append(tImg)\n",
    "        \n",
    "        threadHndlr = ThreadHandler(self.nProcesses)\n",
    "        threadHndlr.startThreads(__loadImage)\n",
    "        allCls, tI, tCls = list(filesPerClass.keys()), 0, 0\n",
    "        for __ in range(nFiles):\n",
    "            threadHndlr.putJob({\"imgCls\": allCls[tCls], \"imgFile\": dataDict[allCls[tCls]][tI]})\n",
    "            tI += 1\n",
    "            if tI < filesPerClass[allCls[tCls]]: continue\n",
    "            tCls += 1 \n",
    "            tI = 0\n",
    "        threadHndlr.endThreads()\n",
    "\n",
    "        filesPerClass, nFiles = {}, 0\n",
    "        for c in outDict:\n",
    "            filesPerClass[c] = len(outDict[c])\n",
    "            nFiles += len(outDict[c])\n",
    "        \n",
    "        print(\" Images Cached.\")\n",
    "        return outDict, filesPerClass, nFiles\n",
    "\n",
    "    def getBalancedIndices(self,):\n",
    "        \n",
    "        if self.maxSampPerClass is None: return self.getImbalancedIndices()\n",
    "\n",
    "        if self.maxSampPerClass == -1:\n",
    "            for c in self.filesPerClass: \n",
    "                self.maxSampPerClass = max(self.maxSampPerClass, self.filesPerClass[c])\n",
    "            pass\n",
    "        \n",
    "        self.__balLen = 0\n",
    "        balIndices = {}\n",
    "        for c in self.dataDict.keys():\n",
    "            tList = np.arange(len(self.dataDict[c]))\n",
    "            nReps = np.ceil(self.maxSampPerClass/len(tList))\n",
    "            balIndices[c] = np.repeat(tList, nReps)\n",
    "            np.random.shuffle(balIndices[c])\n",
    "            \n",
    "            balIndices[c] = balIndices[c][:self.maxSampPerClass].tolist()\n",
    "            self.__balLen += len(balIndices[c])\n",
    "        \n",
    "        return balIndices\n",
    "\n",
    "    def getImbalancedIndices(self,):\n",
    "\n",
    "        self.__balLen = 0\n",
    "        balIndices = {}\n",
    "        for c in self.dataDict.keys():\n",
    "            balIndices[c] = np.arange(len(self.dataDict[c])).tolist()\n",
    "            self.__balLen += len(balIndices[c])\n",
    "\n",
    "        return balIndices\n",
    "\n",
    "    def __getitem__(self, index) -> Dict:\n",
    "\n",
    "        if len(self.balIdxs[self.idx2Label[self.__clsItr]]) == 0:\n",
    "            print(\" Shuffling indices...\", end=\"\")\n",
    "            self.__clsItr = 0\n",
    "            self.balIdxs = self.getBalancedIndices()\n",
    "            print(\"Done.\")\n",
    "\n",
    "        tCls = self.idx2Label[self.__clsItr]\n",
    "        tIdx = self.balIdxs[tCls].pop()\n",
    "        tImg = self.dataDict[tCls][tIdx]\n",
    "        \n",
    "        if isinstance(tImg, str): tImg = np.asarray(Image.open(tImg)).copy()\n",
    "        else: tImg = tImg.copy()\n",
    "\n",
    "        if not self.augObject is None: tImg = self.augObject(tImg)[0]\n",
    "\n",
    "        if \"notImportant\" in self.allClasses:\n",
    "            hotEncode = np.zeros(self.nClasses-1, dtype=np.float32)\n",
    "            if self.__clsItr != 0: hotEncode[self.__clsItr-1] = 1\n",
    "        else:\n",
    "            hotEncode = np.zeros(self.nClasses, dtype=np.float32)\n",
    "            hotEncode[self.__clsItr] = 1\n",
    "\n",
    "        tImg = torch.from_numpy(tImg).moveaxis(-1, 0)\n",
    "        hotEncode = torch.from_numpy(hotEncode)\n",
    "        \n",
    "        self.__clsItr += 1\n",
    "        if self.__clsItr >= len(self.idx2Label): self.__clsItr = 0\n",
    "\n",
    "        # return {\"thisX\": tImg, \"thisY\": hotEncode, \"className\": tCls, \"classIdx\": self.label2Idx[tCls]}\n",
    "        return (tImg,), (hotEncode,)\n",
    "    pass\n",
    "\n",
    "class SimpleLoader(Dataset):\n",
    "\n",
    "    def __init__(self, rootPath: str, validLbls: Set[str]=set(), augObject: Callable=None, \n",
    "                nProcesses: int=8, cacheImgs: bool=True, label2Idx: Dict=None, \n",
    "                idx2Label: Dict=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.rootPath = rootPath\n",
    "        self.validLbls = validLbls\n",
    "        self.augObject = augObject\n",
    "        self.nProcesses = nProcesses\n",
    "        self.cacheImgs = cacheImgs\n",
    "\n",
    "        if self.cacheImgs: self.dataList, self.filesPerClass = self.__cacheImages()\n",
    "        else: self.dataList, self.filesPerClass = self.getFileNames()\n",
    "        self.nClasses, self.allClasses = len(self.filesPerClass), list(self.filesPerClass.keys())\n",
    "        \n",
    "        if label2Idx is None or idx2Label is None: \n",
    "            self.label2Idx, self.idx2Label = self.__tagLabelMap()\n",
    "        else: self.label2Idx, self.idx2Label = label2Idx, idx2Label\n",
    "\n",
    "    def __len__(self,): return len(self.dataList)\n",
    "\n",
    "    def getFileNames(self,):\n",
    "        \n",
    "        if len(self.validLbls) == 0: self.validLbls = set(os.listdir(self.rootPath))\n",
    "\n",
    "        dataList, filesPerClass = [], {}\n",
    "        for c in os.listdir(self.rootPath):\n",
    "            thisFiles = pd.Series(os.listdir(F\"{self.rootPath}/{c}\"))\n",
    "            thisFiles = F\"{self.rootPath}/{c}/\" + thisFiles\n",
    "            mCls = c if c in self.validLbls else \"notImportant\"\n",
    "            thisFiles = pd.DataFrame({0: [mCls]*len(thisFiles), 1: thisFiles}).values.tolist()\n",
    "            dataList += thisFiles\n",
    "            filesPerClass[mCls] = filesPerClass.get(mCls, 0) + len(thisFiles)\n",
    "        \n",
    "        return dataList, filesPerClass    \n",
    "\n",
    "    def __cacheImages(self,):\n",
    "        \n",
    "        allFiles, filesPerImages = self.getFileNames()\n",
    "        outList = []\n",
    "        \n",
    "        def __loadImage(tIdx: int, imgInfo: List):#, clsName: str, imgPath: str):\n",
    "            \n",
    "            for i, (clsName, imgPath) in enumerate(imgInfo):\n",
    "                if ((i+1)%100) == 0: print(F\" Thread -> {tIdx} : Processed {i+1} images of {len(imgInfo)}\")\n",
    "                tImg = np.asarray(Image.open(imgPath)).copy()\n",
    "                outList.append((clsName, tImg))\n",
    "            print(F\" Thread -> {tIdx} : Done.\")\n",
    "        \n",
    "        flsPerThread = int(len(allFiles) / self.nProcesses)\n",
    "        threadObjs = []\n",
    "        for i in range(self.nProcesses):\n",
    "            thObj = Thread(target=__loadImage, args=(i+1, allFiles[i*flsPerThread:(i+1)*flsPerThread]))\n",
    "            thObj.start()\n",
    "            threadObjs.append(thObj)\n",
    "\n",
    "        for th in threadObjs: th.join()\n",
    "        return outList, filesPerImages\n",
    "\n",
    "    def __tagLabelMap(self,):\n",
    "        if \"notImportant\" is self.allClasses:\n",
    "            excClass = [self.allClasses.pop(self.allClasses.index(\"notImportant\"))]\n",
    "            self.allClasses = excClass + self.allClasses\n",
    "\n",
    "        label2Idx, idx2Label = {}, {}\n",
    "        for i in range(len(self.allClasses)): \n",
    "            label2Idx[self.allClasses[i]], idx2Label[i] = i, self.allClasses[i]\n",
    "        return label2Idx, idx2Label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tCls, tImg = self.dataList[index]\n",
    "        cIdx = self.label2Idx[tCls]\n",
    "\n",
    "        if isinstance(tImg, str): tImg = np.asarray(Image.open(tImg)).copy()\n",
    "        else: tImg = tImg.copy()\n",
    "        if not self.augObject is None: tImg = self.augObject(tImg)[0]\n",
    "\n",
    "        if \"notImportant\" in self.allClasses:\n",
    "            hotEncode = np.zeros(self.nClasses-1, dtype=np.float32)\n",
    "            if cIdx != 0: hotEncode[cIdx-1] = 1\n",
    "        else:\n",
    "            hotEncode = np.zeros(self.nClasses, dtype=np.float32)\n",
    "            hotEncode[cIdx] = 1\n",
    "\n",
    "        tImg = torch.from_numpy(tImg).moveaxis(-1, 0)\n",
    "        hotEncode = torch.from_numpy(hotEncode)\n",
    "        \n",
    "        # return {\"thisX\": tImg, \"thisY\": hotEncode, \"className\": tCls, \"classIdx\": self.label2Idx[tCls]}\n",
    "        return (tImg,), (hotEncode,)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40dc113",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from typing import Tuple, Callable, Any\n",
    "\n",
    "import albumentations as AL\n",
    "import numpy as np\n",
    "\n",
    "# class ResizeCustom:\n",
    "\n",
    "#     def __init__(self, newSize: Tuple[int]=None, largestAxis: int=255, smallestSize: int=None,\n",
    "#                 padSize: Tuple[int]=None) -> None:\n",
    "        \n",
    "#         self.newSize = newSize\n",
    "#         self.largestAxis = largestAxis\n",
    "#         self.smallestSize = smallestSize\n",
    "#         self.padSize = padSize\n",
    "\n",
    "#         if not newSize is None: self.resizeObj = AL.Resize(newSize[0], newSize[1])\n",
    "#         elif not largestAxis is None: self.resizeObj = AL.LongestMaxSize(largestAxis)\n",
    "#         elif not smallestSize is None: self.resizeObj = AL.LongestMaxSize(smallestSize)\n",
    "#         else: self.resizeObj = None\n",
    "#         pass\n",
    "\n",
    "#     def __call__(self, inpImage: np.ndarray) -> np.ndarray:\n",
    "\n",
    "#         if not self.resizeObj is None: inpImage = self.resizeObj(image=inpImage)[\"image\"]\n",
    "#         if self.padSize is None: return inpImage\n",
    "#         pass\n",
    "\n",
    "#     pass\n",
    "\n",
    "class PadImage:\n",
    "\n",
    "    def __init__(self, outSize: Tuple[int]=(224, 224)) -> None:\n",
    "        self.outSize = outSize\n",
    "        self.maxSize = max(outSize)\n",
    "        self.resizeObj = AL.LongestMaxSize(self.maxSize)\n",
    "        pass\n",
    "\n",
    "    def __call__(self, inpImage: np.ndarray, *args: Any, **kwargs: Any) -> np.ndarray:\n",
    "        \n",
    "        # if max(inpImage.shape) > self.maxSize: inpImage = self.resizeObj(image=inpImage)[\"image\"]\n",
    "        inpImage = self.resizeObj(image=inpImage)[\"image\"]\n",
    "        imgSh = inpImage.shape\n",
    "\n",
    "        diffY, diffX = (self.outSize[0] - imgSh[0]), (self.outSize[1] - imgSh[1])\n",
    "        if diffY < 0: diffY = 0\n",
    "        if diffX < 0: diffX = 0\n",
    "\n",
    "        pTop, pBot = int(np.floor(diffY/2)), int(np.ceil(diffY/2))\n",
    "        pLft, pRht = int(np.floor(diffX/2)), int(np.ceil(diffX/2))\n",
    "\n",
    "        return np.pad(inpImage, ((pTop, pBot), (pLft, pRht), (0, 0)))\n",
    "    pass\n",
    "\n",
    "class DataAugmentor:\n",
    "\n",
    "    def __init__(self, \n",
    "                 probHVShift: float=0.5, \n",
    "                 probHVFlip: float=0.5, \n",
    "                 probRotate: float=0.5, \n",
    "                 probZoom: float=0.5, \n",
    "                 probRGBShift: float=0.5, \n",
    "                 probBrightness: float=0.5,\n",
    "                 probSharpen: float=0.5, \n",
    "                 probEmboss: float=0.5, \n",
    "                 hvShiftPer: Tuple[float]=(0., 0.1), \n",
    "                 zoomLimits: Tuple[float]=(0.85, 1.15), \n",
    "                 rotLimit: float=20, \n",
    "                 sharpenAlpha: Tuple[float]=(0.1, 0.2), \n",
    "                 sharpenLight: Tuple[float]=(0., 0.), \n",
    "                 embossAlpha: Tuple[float]=(0., 1.), \n",
    "                 embossStrength: Tuple[float]=(0.1, 0.7), \n",
    "                 normImage: bool=True, \n",
    "                 bBoxFormat: str=\"yolo\", \n",
    "                 KPFormat: str=\"xy\", \n",
    "                 newSize: Tuple[int]=None, \n",
    "                 beforeAug: Callable=None, \n",
    "                 afterAug: Callable=None\n",
    "                ):\n",
    "\n",
    "        allTransforms = []\n",
    "        self.beforeAug = beforeAug\n",
    "\n",
    "        if probHVShift > 0.0: \n",
    "            allTransforms.append( AL.Affine(translate_percent=hvShiftPer, p=probHVShift, mode=0, cval=0) )\n",
    "        if probHVFlip > 0.0: \n",
    "            allTransforms += [AL.HorizontalFlip(p=probHVFlip), AL.VerticalFlip(p=probHVFlip)]\n",
    "        if probRotate > 0.0: \n",
    "            allTransforms.append( AL.Rotate(limit=rotLimit, p=probRotate, border_mode=0) )\n",
    "        if probZoom > 0.0: \n",
    "            allTransforms.append( AL.Affine(scale=zoomLimits, p=probZoom) )\n",
    "        if probRGBShift > 0.0: \n",
    "            allTransforms.append( AL.RGBShift(p=probRGBShift) )    \n",
    "        if probBrightness > 0.0: \n",
    "            allTransforms.append( AL.RandomBrightnessContrast(p=probBrightness) )\n",
    "        if probSharpen > 0.0:\n",
    "            allTransforms.append( AL.Sharpen(sharpenAlpha, sharpenLight, p=probSharpen) )\n",
    "        if probEmboss > 0.0:\n",
    "            allTransforms.append( AL.Emboss(embossAlpha, embossStrength, p=probEmboss) )\n",
    "\n",
    "        if normImage: allTransforms.append(AL.Normalize([0.485, 0.456, 0.406],\n",
    "                                                        [0.229, 0.224, 0.225], p=1.0))\n",
    "        if not newSize is None: allTransforms.append(AL.Resize(newSize[0], newSize[1]) )\n",
    "\n",
    "        self.augFunction = AL.Compose(allTransforms,\n",
    "                                      bbox_params=AL.BboxParams(format=bBoxFormat,),\n",
    "                                      keypoint_params=AL.KeypointParams(format=KPFormat,\n",
    "                                                                        remove_invisible=True, \n",
    "                                                                        angle_in_degrees=True\n",
    "                                                                       )\n",
    "                                     )\n",
    "        \n",
    "        self.afterAug = afterAug\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, augImage, bBoxes=[], keyPoints=[], segMask=None):\n",
    "        \n",
    "        augImage = np.asarray(augImage).copy()\n",
    "        if not self.beforeAug is None: augImage = self.beforeAug(inpImage=augImage)\n",
    "\n",
    "        if not segMask is None: \n",
    "            augOut = self.augFunction(image=augImage, bboxes=bBoxes, keypoints=keyPoints, mask=segMask)\n",
    "        else: augOut = self.augFunction(image=augImage, bboxes=bBoxes, keypoints=keyPoints)\n",
    "\n",
    "        if not self.afterAug is None: augImage = self.afterAug(inpImage=augImage)\n",
    "        return ( augOut[\"image\"], augOut[\"bboxes\"], augOut[\"keypoints\"], \n",
    "                    ( None if segMask is None else augOut[\"mask\"]) )\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119afbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = DataAugmentor(0., 0., 0., 0., 0., 0., 0., 0.,normImage=True)\n",
    "# trainAug = DataAugmentor(0., 0., 0., 0., 0., 0., 0., 0., normImage=True, beforeAug=PadImage())\n",
    "testAug = DataAugmentor(0., 0., 0., 0., 0., 0., 0., 0., normImage=True)\n",
    "\n",
    "trainSet = BalancedLoader(F\"{data_directory}/train\", validLbls=set(), maxSampPerClass=100, augObject=trainAug, cacheImgs=False)\n",
    "testSet = SimpleLoader(F\"{data_directory}/test\", augObject=testAug, \n",
    "               validLbls=set(), cacheImgs=False, label2Idx=trainSet.label2Idx.copy(), idx2Label=trainSet.idx2Label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02917110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader1 = torch.utils.data.DataLoader(trainSet, batch_size = 16, shuffle=True)\n",
    "# vloader = torch.utils.data.DataLoader(validation_data, batch_size =32,shuffle = True)\n",
    "testloader1 = torch.utils.data.DataLoader(testSet, batch_size = 16, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca381ef",
   "metadata": {},
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# # validation_transforms = transforms.Compose([transforms.Resize(256),\n",
    "# #                                             transforms.CenterCrop(224),\n",
    "# #                                             transforms.ToTensor(),\n",
    "# #                                             transforms.Normalize([0.485, 0.456, 0.406], \n",
    "# #                                                                  [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# # TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(F\"{data_directory}/train\", transform=train_transforms)\n",
    "# # validation_data = datasets.ImageFolder(validation_directory, transform=validation_transforms)\n",
    "test_data = datasets.ImageFolder(F\"{data_directory}/test\" ,transform = test_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader2 = torch.utils.data.DataLoader(train_data, batch_size = 8, shuffle=True)\n",
    "# vloader = torch.utils.data.DataLoader(validation_data, batch_size =32,shuffle = True)\n",
    "testloader2 = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e3a21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader 1 Len:-  13\n",
      "Test Loader 1 Len:-  21\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Loader 1 Len:- \", len(trainloader1))\n",
    "# print(\"Train Loader 2 Len:- \", len(trainloader2))\n",
    "print(\"Test Loader 1 Len:- \", len(testloader1))\n",
    "# print(\"Test Loader 2 Len:- \", len(testloader2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9e6d7f",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "with open('/opt/infilect/dev/repos/image_classification/tag_to_json.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "conscious-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae317301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class GradualWarmupScheduler(_LRScheduler):\n",
    "    \"\"\" Gradually warm-up(increasing) learning rate in optimizer.\n",
    "    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if \n",
    "                    multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n",
    "        total_epoch: target learning rate is reached at total_epoch, gradually\n",
    "        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        self.multiplier = multiplier\n",
    "        if self.multiplier < 1.:\n",
    "            raise ValueError('multiplier should be greater than or equal to 1.')\n",
    "        self.total_epoch = total_epoch\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super(GradualWarmupScheduler, self).__init__(optimizer)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier \n",
    "                                                     for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_last_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "\n",
    "        if self.multiplier == 1.0:\n",
    "            if self.last_epoch == 0: \n",
    "                return [(base_lr * (float(self.last_epoch+1) / self.total_epoch))/2.\n",
    "                        for base_lr in self.base_lrs]\n",
    "            else:\n",
    "                return [base_lr * (float(self.last_epoch) / self.total_epoch)\n",
    "                        for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) \n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n",
    "        # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n",
    "        if epoch is None: epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch if epoch != 0 else 1  \n",
    "        \n",
    "        if self.last_epoch <= self.total_epoch:\n",
    "            warmup_lr = [base_lr * ((self.multiplier - 1) * self.last_epoch / self.total_epoch + 1.) \n",
    "                         for base_lr in self.base_lrs]\n",
    "            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr): \n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            if epoch is None: self.after_scheduler.step(metrics, None)\n",
    "            else: self.after_scheduler.step(metrics, epoch - self.total_epoch)\n",
    "\n",
    "    def step(self, epoch=None, metrics=None):\n",
    "        if type(self.after_scheduler) != ReduceLROnPlateau:\n",
    "            if self.finished and self.after_scheduler:\n",
    "                if epoch is None: self.after_scheduler.step(None)\n",
    "                else: self.after_scheduler.step(epoch - self.total_epoch)\n",
    "                self._last_lr = self.after_scheduler.get_last_lr()\n",
    "            else: return super(GradualWarmupScheduler, self).step(epoch)\n",
    "        else: self.step_ReduceLROnPlateau(metrics, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c8d74",
   "metadata": {},
   "source": [
    "def setup_model(model_name, num_classes):\n",
    "    \n",
    "    model = models.get_model(model_name, weights = \"DEFAULT\")\n",
    "    \n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "    model.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    #     optimizer, milestones=[4], gamma=0.3\n",
    "    # )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, last_epoch=40, step_size=3, gamma=0.7)\n",
    "    lrSched = GradualWarmupScheduler(optimizer, 1, 4, scheduler)\n",
    "    \n",
    "    model.cuda()\n",
    "    return model, optimizer, lrSched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601c376",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ClassHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, inpUnits=1280, opOut=2):\n",
    "        super().__init__()\n",
    "        self.seqBlock_0 = nn.Sequential(torch.nn.Dropout(0.3), torch.nn.Linear(inpUnits, opOut))\n",
    "\n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor: return self.seqBlock_0(inpX)\n",
    "    pass\n",
    "\n",
    "class BasicModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name: str, nClasses: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backBone = models.get_model(model_name, weights = \"DEFAULT\")\n",
    "        # self.backBone = torchModels.resnet50(weights=torchModels.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backBone.fc = nn.Identity()\n",
    "        self.classHead = ClassHead(2048, nClasses)\n",
    "        \n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor:\n",
    "        embX = self.backBone(inpX)\n",
    "        out = self.classHead(embX)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73b6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name , num_classes=2):\n",
    "\n",
    "    # The number of channels in ResNet18 is divisible by 8.\n",
    "    # This is required for fast GEMM integer matrix multiplication.\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "    model = models.get_model(model_name, weights = \"DEFAULT\")\n",
    "\n",
    "    # We would use the pretrained ResNet18 as a feature extractor.\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Modify the last FC layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6216c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(model_name = \"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca0fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedModel(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedModel, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "\n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor:\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        embX = self.quant(inpX)\n",
    "        quantX = self.model_fp32(embX)\n",
    "        dequantX = self.dequant(quantX)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "#         deQuantX = self.dequant(quantX)\n",
    "        return dequantX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8781a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65daff34",
   "metadata": {},
   "source": [
    "# model, optimizer, scheduler = setup_model(model_name = \"resnet50\", num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df45130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BasicModel(model_name = \"resnet50\", nClasses = 2)\n",
    "# model = nn.DataParallel(model, device_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "collectible-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossObj = FocalLossMultiClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f120fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanMeter:\n",
    "\n",
    "    def __init__(self,):\n",
    "        \n",
    "        \"\"\" Simple mean tracker for metrics and losses.\n",
    "        \"\"\"\n",
    "\n",
    "        self.sumValues = {}\n",
    "        self.countValues = {}\n",
    "        pass\n",
    "    \n",
    "    def __len__(self,) -> int: \n",
    "        \"\"\" Returns the number of currently tracked metrics/losses/values.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of currently tracked values.\n",
    "        \"\"\"\n",
    "        return len(self.sumValues)\n",
    "    \n",
    "    def __setitem__(self, index: Union[int, str], value: Union[int, float]) -> None:\n",
    "        \"\"\" Add a new metric to track or update some metric that is being tracked.\n",
    "\n",
    "        Args:\n",
    "            index (Union[int, str]): \n",
    "                Key/name of the metric to track.\n",
    "            value (Union[int, float]): \n",
    "                New value for the corresponding metric.\n",
    "        \"\"\"\n",
    "        if not index in self.sumValues.keys(): self.sumValues[index], self.countValues[index] = 0, 0\n",
    "        self.sumValues[index] += value\n",
    "        self.countValues[index] += 1\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index: Union[int, str]) -> float:\n",
    "        \"\"\" Returns the current mean of a metric denoted by index.\n",
    "\n",
    "        Args:\n",
    "            index (Union[int, str]): \n",
    "                Key/name of metric.\n",
    "\n",
    "        Raises:\n",
    "            KeyError: \n",
    "                Raises error if given metric key is not present.\n",
    "\n",
    "        Returns:\n",
    "            float: Mean of metric denoted by \"index\".\n",
    "        \"\"\"\n",
    "        if not index in self.sumValues: raise KeyError(F\"Key {index} does not exist.\")\n",
    "        return self.sumValues[index] / self.countValues[index]\n",
    "\n",
    "    @property\n",
    "    def keys(self,) -> List[str]: \n",
    "        \"\"\" Get list of metrics currently being tracked.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of key names.\n",
    "        \"\"\"\n",
    "        return list(self.sumValues.keys())\n",
    "\n",
    "    def hasKey(self, index: Union[int, str]) -> bool:\n",
    "        \"\"\" Check if metric denoted by \"index\" is being tracked.\n",
    "\n",
    "        Args:\n",
    "            index (Union[int, str]): \n",
    "                Key/name to track.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if metric exists.\n",
    "        \"\"\"\n",
    "        return index in self.sumValues.keys()\n",
    "\n",
    "    def getAll(self,) -> Dict:\n",
    "        \"\"\" Get mean of all currently tracked metrics.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary where each key is the metric key/name/index and the\n",
    "                corresponding value is it's mean. \n",
    "        \"\"\"\n",
    "        return {k: self.sumValues[k]/self.countValues[k] for k in self.sumValues.keys()}\n",
    "        \n",
    "    def resetValues(self,) -> None:\n",
    "        \"\"\" Clear and remove all metrics currently being tracked.\n",
    "        \"\"\"\n",
    "        self.sumValues, self.countValues = {}, {}\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75c15578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def getLatency(callFunc: Callable) -> Callable:\n",
    "\n",
    "    @wraps(callFunc)\n",
    "    def wrapperFunc(*args, **kw):\n",
    "        stTime = time()\n",
    "        rootReturn = callFunc(*args, **kw)\n",
    "        enTime = time()\n",
    "        return rootReturn, enTime-stTime\n",
    "    return wrapperFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27173611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import copy\n",
    "class TrainEngine:\n",
    "\n",
    "    def __init__(self, engineModel, projectName: str, runName: str, savePath: str=None, \n",
    "                usageMode: str=\"Train\", torDevice: str=None, useWandb: bool=True):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            engineModel (_type_): _description_\n",
    "            projectName (str): _description_\n",
    "            runName (str): _description_\n",
    "            savePath (str, optional): _description_. Defaults to None.\n",
    "            usageMode (str, optional): _description_. Defaults to \"Train\".\n",
    "            torDevice (str, optional): _description_. Defaults to None.\n",
    "            useWandb (bool, optional): _description_. Defaults to True.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.usageMode = usageMode # Train/Validate/Infer/Test\n",
    "        self.trainConfig = {}\n",
    "        self.optimObj = None\n",
    "        self.schedulerObj = None\n",
    "        self.modelScaler = None\n",
    "        self.lossObj = None\n",
    "        \n",
    "        savePath = F\"{projectName}/{runName}\" if savePath is None else F\"{savePath}/{projectName}/{runName}\"\n",
    "        self.trainConfig[\"projectName\"] = projectName\n",
    "        self.trainConfig[\"runName\"] = runName\n",
    "        self.trainConfig[\"savePath\"] = savePath\n",
    "        self.trainConfig[\"batchSize\"] = 32\n",
    "        self.trainConfig[\"nEpochs\"] = 20\n",
    "        self.trainConfig[\"weightDecay\"] = 0.001\n",
    "        self.trainConfig[\"trainHalfPrec\"] = False\n",
    "        self.trainConfig[\"cosineCycle\"] = 4\n",
    "        self.trainConfig[\"currEpoch\"] = 0\n",
    "        self.trainConfig[\"logAfterBatch\"] = 20\n",
    "        self.trainConfig[\"printAfterBatch\"] = 5000\n",
    "        self.trainConfig[\"useWandB\"] = useWandb\n",
    "        self.trainConfig[\"logToFile\"] = True\n",
    "        self.trainConfig[\"logFile\"] = {i:self.trainConfig[\"savePath\"] + F\"/{i}_Logs.csv\"\n",
    "                                        for i in [\"Train\", \"Test\", \"Valid\", \"Eval\"]}\n",
    "        self.trainConfig[\"currentBest\"] = None\n",
    "        self.trainConfig[\"monitorKey\"] = None\n",
    "        self.trainConfig[\"saveIfLess\"] = True\n",
    "        self.trainConfig[\"evalOnTrain\"] = True\n",
    "\n",
    "        self.__logKeysEpoch = None\n",
    "        self.__logKeys = None\n",
    "        self.__logFile = None \n",
    "        self.meanMeters = {\"Train\": None, \"Valid\": None, \"Test\": None, \"Eval\": None}\n",
    "\n",
    "        self.torDevice = (torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" ) \n",
    "                          if torDevice is None else torDevice)\n",
    "        self.engineModel = engineModel.to(self.torDevice)\n",
    "        self.bestModel = copy.deepcopy(self.engineModel)\n",
    "        \n",
    "        if self.trainConfig[\"useWandB\"]: self.prepareWandB()\n",
    "        pass\n",
    "    \n",
    "    def __del__(self,): self.cleanUp()\n",
    "    \n",
    "    def cleanUp(self,):\n",
    "        try: wandb.finish()\n",
    "        except: pass\n",
    "        try:\n",
    "            if not self.__logFile is None:  \n",
    "                for v in self.__logFile.values(): v.close()\n",
    "        except: pass\n",
    "    \n",
    "    def prepareWandB(self,):\n",
    "        wandb.init(project=self.trainConfig[\"projectName\"])\n",
    "        wandb.config = self.trainConfig\n",
    "        wandb.run.name = self.trainConfig[\"runName\"]\n",
    "        pass\n",
    "    \n",
    "    def setupOptimizer(self, optimObj=None, optimParams=None, learningRate=None, \n",
    "                       betaVals: Tuple[float]=(0.9, 0.999), weightDecay=None):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            optimObj (_type_, optional): _description_. Defaults to None.\n",
    "            optimParams (_type_, optional): _description_. Defaults to None.\n",
    "            learningRate (_type_, optional): _description_. Defaults to None.\n",
    "            betaVals (Tuple[float], optional): _description_. Defaults to (0.9, 0.999).\n",
    "            weightDecay (_type_, optional): _description_. Defaults to None.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get parameters for default optimizer.\n",
    "        if weightDecay is None:\n",
    "            if \"weightDecay\" in self.trainConfig: weightDecay = self.trainConfig[\"weightDecay\"]\n",
    "            else: weightDecay = 0.\n",
    "        if learningRate is None:\n",
    "            if \"learningRate\" in self.trainConfig: learningRate = self.trainConfig[\"learningRate\"]\n",
    "            else: learningRate = 0.0001\n",
    "        \n",
    "        # Set object\n",
    "        if optimObj is None: \n",
    "            optimObj = torch.optim.Adam(params=self.engineModel.parameters(), lr=learningRate, \n",
    "                                        betas=betaVals, weight_decay=weightDecay)\n",
    "        self.optimObj = optimObj\n",
    "        \n",
    "        # Load parameters if available.\n",
    "        if optimParams is None: return\n",
    "        if isinstance(optimParams, str): \n",
    "            optimParams = torch.load(optimParams, map_location=self.torDevice)\n",
    "        self.optimObj.load_state_dict(optimParams)\n",
    "        pass\n",
    "    \n",
    "    def setupLRScheduler(self, schedulerObj=None, schedulerParams=None):\n",
    "        \n",
    "        # Get object.\n",
    "        if schedulerObj is None: return\n",
    "        if self.optimObj is None: \n",
    "            raise Exception(\"Uninitialized optimizer. Setup optimizer first using setupOptimizer() \\\n",
    "method of the class.\")\n",
    "        \n",
    "        if schedulerObj == \"CosineAnnealing\": \n",
    "            schedulerObj = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimObj, \n",
    "                        self.trainConfig.get(\"cosineCycle\", 4), eta_min=0.00001, verbose=True)\n",
    "        \n",
    "        self.schedulerObj = schedulerObj\n",
    "        \n",
    "        # Load parameters if available.\n",
    "        if schedulerParams is None: return\n",
    "        if isinstance(schedulerParams, str): \n",
    "            schedulerParams = torch.load(schedulerParams, map_location=self.torDevice)\n",
    "        self.schedulerObj.load_state_dict(schedulerParams)\n",
    "        pass\n",
    "    \n",
    "    def createLogFiles(self, openMode: str=\"w\") -> None:\n",
    " \n",
    "        if not self.trainConfig[\"logToFile\"] is None:\n",
    "\n",
    "            self.__logFile = {}\n",
    "            for k in self.trainConfig[\"logFile\"]: \n",
    "                # Log files for each phase.\n",
    "                openMode = openMode if os.path.exists(self.trainConfig[\"logFile\"][k]) else \"w\"\n",
    "                self.__logFile[k] = open(self.trainConfig[\"logFile\"][k], openMode)\n",
    "\n",
    "            # Log file for epoch.\n",
    "            self.__logFile[\"Epoch_Logs\"] = open(F\"{self.trainConfig['savePath']}/Epoch_Logs.csv\", \n",
    "            openMode if os.path.exists(F\"{self.trainConfig['savePath']}/Epoch_Logs.csv\") else \"w\")\n",
    "        pass\n",
    "\n",
    "    def prepareForTrain(self, optimObj=None, schedulerObj=\"CosineAnnealing\", \n",
    "                        engineParams: Union[str, Dict]=None, modelParams: Union[str, Dict]=None, \n",
    "                        optimParams: Union[str, Dict]=None, schedulerParams: Union[str, Dict]=None, \n",
    "                        lossObj: Callable=None, currEpoch: int=None, nEpochs: int=100, \n",
    "                        monitorKey: str=None, saveIfLess: bool=True, batchSize: int=32, \n",
    "                        learningRate: float=0.0001, betaVals: Tuple[float]=(0.9, 0.999), \n",
    "                        weightDecay: float=0., cosineCycle: int=4):\n",
    "        \n",
    "        # Load pre-trained weights and config.\n",
    "        if not engineParams is None:\n",
    "            \n",
    "            # Load params from file if required.\n",
    "            if isinstance(engineParams, str):\n",
    "                engineParams = torch.load(engineParams, map_location=self.torDevice)\n",
    "            \n",
    "            # Set params.\n",
    "            modelParams = engineParams[\"modelParams\"]\n",
    "            optimParams = engineParams[\"optimParams\"]\n",
    "            schedulerParams = engineParams[\"schedulerParams\"]\n",
    "            \n",
    "            # Set train config.\n",
    "            trainConfig = engineParams[\"trainConfig\"]\n",
    "            for k in [\"projectName\", \"runName\", \"savePath\", \"logFile\"]: \n",
    "                trainConfig[k] = self.trainConfig[k]\n",
    "            self.trainConfig = trainConfig\n",
    "        \n",
    "        # Load model params if available.\n",
    "        if not modelParams is None:\n",
    "            if isinstance(modelParams, str): \n",
    "                modelParams = torch.load(modelParams, map_location=self.torDevice)\n",
    "            self.engineModel.load_state_dict(modelParams)\n",
    "\n",
    "        # Get train details.\n",
    "        self.trainConfig[\"batchSize\"] = batchSize\n",
    "        self.trainConfig[\"nEpochs\"] = nEpochs\n",
    "        self.trainConfig[\"weightDecay\"] = weightDecay\n",
    "        self.trainConfig[\"cosineCycle\"] = cosineCycle\n",
    "        self.trainConfig[\"monitorKey\"] = \"totalLoss\" if monitorKey is None else monitorKey\n",
    "        self.trainConfig[\"saveIfLess\"] = saveIfLess \n",
    "        if not currEpoch is None: self.trainConfig[\"currEpoch\"] = currEpoch\n",
    "        \n",
    "        # Setup objects.\n",
    "        for k in self.meanMeters.keys(): self.meanMeters[k] = MeanMeter()\n",
    "        if self.trainConfig[\"trainHalfPrec\"]: self.modelScaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        self.setupOptimizer(optimObj, optimParams, learningRate, betaVals, weightDecay)\n",
    "        self.setupLRScheduler(schedulerObj, schedulerParams)\n",
    "        self.lossObj = torch.nn.CrossEntropyLoss() if lossObj is None else lossObj\n",
    "        \n",
    "        # Manage files and directories.\n",
    "        os.makedirs(self.trainConfig[\"savePath\"], exist_ok=True)\n",
    "        os.makedirs(F\"{self.trainConfig['savePath']}/checkPoints\", exist_ok=True)\n",
    "        \n",
    "        # Create log files.\n",
    "        self.createLogFiles()\n",
    "        pass\n",
    "    \n",
    "    def getLoss(self, thisY: Union[List, Tuple, torch.Tensor], yHat: Union[List, Tuple, torch.Tensor]):\n",
    "        # Compute Loss\n",
    "        if (not isinstance(thisY, list)) and (not isinstance(thisY, tuple)): thisY = [thisY]\n",
    "        if (not isinstance(yHat, list)) and (not isinstance(yHat, tuple)): yHat = [yHat]\n",
    "        \n",
    "        # Default cross entropy.\n",
    "        totalLoss = self.lossObj(yHat[0], thisY[0])\n",
    "        for i in range(len(thisY)): totalLoss += self.lossObj(yHat[i], thisY[i])\n",
    "        return totalLoss, {\"totalLoss\": totalLoss.item()}\n",
    "    \n",
    "    def getMetrics(self, thisY: Union[List, Tuple, torch.Tensor], yHat: Union[List, Tuple, torch.Tensor]):\n",
    "        \n",
    "        # Compute Metrics\n",
    "        if (not isinstance(thisY, list)) and (not isinstance(thisY, tuple)): thisY = [thisY]\n",
    "        if (not isinstance(yHat, list)) and (not isinstance(yHat, tuple)): yHat = [yHat]\n",
    "        \n",
    "        # Default accuracy.\n",
    "        avgAccuracy = 0\n",
    "        for i in range(len(thisY)): avgAccuracy += (thisY[i] == yHat[i].argmax(1)).sum() / len(thisY[i])\n",
    "        return {\"accuracyValue\": (avgAccuracy/len(thisY)).item()}\n",
    "    \n",
    "    def startTraining(self, trainLoader, validLoader=None, testLoader=None, ):\n",
    "        \n",
    "        # Train/Valid Loops\n",
    "        if self.optimObj is None: raise Exception(\"Uninitialized optimizer. Setup optimizer first \\\n",
    "using setupOptimizer() method of the class.\")\n",
    "        \n",
    "        # Prepare log files.\n",
    "        self.createLogFiles(openMode=\"a\")\n",
    "        \n",
    "        try:\n",
    "            self.beforeTrain()\n",
    "            for e in range(self.trainConfig[\"currEpoch\"], self.trainConfig[\"nEpochs\"]+1):\n",
    "                \n",
    "                print(F\"\\n Starting Epoch {e}. Training Phase...\")\n",
    "                stTime = time()\n",
    "                self.beforeEpoch(epochIdx=e)\n",
    "                \n",
    "                # Save learning rate at the start of each epoch to log later.\n",
    "                epochLogs = {}\n",
    "                if not self.optimObj is None: epochLogs[\"LR\"] = self.optimObj.param_groups[0]['lr']\n",
    "                else: epochLogs[\"LR\"] = None\n",
    "\n",
    "                #  Forward on trainLoader if available.\n",
    "                if not trainLoader is None:\n",
    "                    self.beforeTrainEpoch(epchIdx=e)\n",
    "                    __, trainTime = self.trainInferWithLoader(trainLoader, thisPhase=\"Train\")\n",
    "                    self.afterTrainEpoch(epchIdx=e)\n",
    "                else: trainTime = None\n",
    "\n",
    "                #  Forward on validLoader if available.\n",
    "                if not validLoader is None:\n",
    "                    self.beforeValidationEpoch(epochIdx=e)\n",
    "                    print(F\"\\n  Starting Validation Phase...\")\n",
    "                    __, validTime = self.trainInferWithLoader(validLoader, thisPhase=\"Valid\")\n",
    "                    self.afterValidationEpoch(epochIdx=e)\n",
    "                else: validTime = None\n",
    "\n",
    "                #  Forward on testLoader if available.\n",
    "                if not testLoader is None:\n",
    "                    self.beforeTestingEpoch(epochIdx=e)\n",
    "                    print(F\"\\n  Starting Testing Phase...\")\n",
    "                    __, testTime = self.trainInferWithLoader(testLoader, thisPhase=\"Test\")\n",
    "                    self.afterTestingEpoch(epochIdx=e)\n",
    "                else: testTime = None\n",
    "\n",
    "                # Evaluate on trainLoader if required.\n",
    "                if (not trainLoader is None) and self.trainConfig[\"evalOnTrain\"]:\n",
    "                    self.beforeEvalEpoch(epochIdx=e)\n",
    "                    print(F\"\\n  Starting Evaluation Phase...\")\n",
    "                    __, evalTime = self.trainInferWithLoader(trainLoader, thisPhase=\"Eval\")\n",
    "                    self.afterEvalEpoch(epochIdx=e)\n",
    "                else: evalTime = None\n",
    "                \n",
    "                # Update current epoch value.\n",
    "                self.trainConfig[\"currEpoch\"] = e\n",
    "\n",
    "                # Epoch verbose.\n",
    "                epochLogs[\"EpochTime\"] = time() - stTime\n",
    "                epochLogs[\"TrainTime\"], epochLogs[\"ValidTime\"] = trainTime, validTime\n",
    "                epochLogs[\"TestTime\"], epochLogs[\"Evaltime\"] = testTime, evalTime\n",
    "                self.verboseEpoch(e, epochLogs=epochLogs)\n",
    "                \n",
    "                # Save checkpoints and update meters.\n",
    "                self.saveCheckPoint(e)\n",
    "                for k in self.meanMeters: self.meanMeters[k].resetValues()\n",
    "                \n",
    "                self.afterEpoch(epochIdx=e)\n",
    "                pass\n",
    "            \n",
    "            self.afterTrain()\n",
    "        except KeyboardInterrupt: print(\"Stop Requested. Performing Cleanup...\")\n",
    "        finally: self.cleanUp()\n",
    "        pass\n",
    "    \n",
    "    @getLatency\n",
    "    def trainInferWithLoader(self, thisLoader, saveResults: bool=False, thisPhase: str=\"Test\"):\n",
    "        # Train/Valid/Infer/Eval Epochs\n",
    "        \n",
    "        # Set model mode.\n",
    "        if self.usageMode == \"Train\": \n",
    "            self.engineModel.train() if thisPhase == \"Train\" else self.engineModel.eval()\n",
    "        else: self.engineModel.eval()\n",
    "        \n",
    "        if not self.optimObj is None:\n",
    "          print(F\"   Learning Rate {self.optimObj.param_groups[0]['lr']}\")\n",
    "\n",
    "        for i, (thisX, thisY) in enumerate(thisLoader):\n",
    "            \n",
    "            # Forward on batch\n",
    "#             print(\"thisY\", thisY)\n",
    "\n",
    "            # Latency helpers.\n",
    "            stTime = time()\n",
    "\n",
    "            # Convert X to list if required and put them into device.\n",
    "            if (not isinstance(thisX, list)) and (not isinstance(thisX, tuple)): thisX = [thisX]\n",
    "            thisX = [t.to(self.torDevice) for t in thisX]\n",
    "\n",
    "            # Convert Y to list if required and put them into device.\n",
    "            if thisY is not None:\n",
    "                if (not isinstance(thisY, list)) and (not isinstance(thisY, tuple)): thisY = [thisY]\n",
    "                thisY = [t.to(self.torDevice) for t in thisY]\n",
    "\n",
    "            # Forward feed on batch.\n",
    "            self.beforeBatch(batchIdx=i, thisX=thisX, thisY=thisY, thisPhase=thisPhase)\n",
    "            if self.usageMode == \"Train\" and thisPhase == \"Train\": \n",
    "                yHat, forwardTime = self.batchForwardTrain(thisX)\n",
    "#                 print(\"TRAIN yHAT\", yHat)\n",
    "            else: \n",
    "                yHat, forwardTime = self.batchForwardInfer(thisX)\n",
    "#                 print(\"INFET yHAT\", yHat)\n",
    "                \n",
    "            \n",
    "            # Backward propagate on batch.\n",
    "            backpropTime = None\n",
    "            if self.usageMode == \"Train\" and thisPhase == \"Train\": \n",
    "                thisLosses, backpropTime = self.batchBackward(thisY, yHat)\n",
    "            elif not thisY is None: __, thisLosses = self.getLoss(thisY, yHat)\n",
    "            else: thisLosses = None\n",
    "\n",
    "            # Update batch level latencies.\n",
    "            batchTime = time() - stTime\n",
    "            self.meanMeters[thisPhase][\"ForwardTime\"] = forwardTime\n",
    "            if not backpropTime is None: self.meanMeters[thisPhase][\"BackPropTime\"] = backpropTime\n",
    "            self.meanMeters[thisPhase][\"BatchTime\"] = batchTime\n",
    "\n",
    "            # Get metrics.\n",
    "            thisY = None if thisY is None else [i.detach() for i in thisY]\n",
    "            #yHat = [i.detach() for i in yHat]\n",
    "#             print(\"thisY\", thisY, \"======================\", \"yHat\", yHat)\n",
    "            yHat = yHat.detach()\n",
    "            if thisY is None: thisMetrics = None\n",
    "            else: thisMetrics = self.getMetrics(thisY, yHat)\n",
    "            self.afterBatch(batchIdx=i, thisX=thisX, thisY=thisY, thisPhase=thisPhase, yHat=yHat, \n",
    "                            thisLosses=thisLosses, thisMetrics=thisMetrics)\n",
    "            \n",
    "            # Update mean meters.\n",
    "            self.updateMeanMeters(thisPhase=thisPhase, newLosses=thisLosses, newMetrics=thisMetrics)\n",
    "\n",
    "            # Save if required and log the batch.\n",
    "            if saveResults: \n",
    "                self.saveResults(batchIdx=i, inputData=thisX, groundTruth=thisY, modelPreds=yHat, \n",
    "                                thisPhase=thisPhase, thisLoss=thisLosses, thisMetrics=thisMetrics)\n",
    "            self.logAndVerbose(i, thisLosses, thisMetrics, thisPhase=thisPhase)\n",
    "\n",
    "        # Step scheduler if required.\n",
    "        if (not self.schedulerObj is None) and thisPhase == \"Train\" and self.usageMode == \"Train\":\n",
    "            self.schedulerObj.step()\n",
    "        pass\n",
    "    \n",
    "    @getLatency\n",
    "    @torch.no_grad()\n",
    "    def batchForwardInfer(self, thisX):\n",
    "        # Batch Forward\n",
    "        \n",
    "        # Forward feed data.\n",
    "        yHat = self.engineModel(*thisX)\n",
    "        return yHat\n",
    "    \n",
    "    @getLatency\n",
    "    def batchForwardTrain(self, thisX):\n",
    "        # Batch Forward\n",
    "        self.optimObj.zero_grad()\n",
    "        \n",
    "        # Forward feed data.\n",
    "        yHat = self.engineModel(*thisX)\n",
    "        return yHat\n",
    "    \n",
    "    @getLatency\n",
    "    def batchBackward(self, thisY, yHat):\n",
    "        # Batch Backward\n",
    "\n",
    "        # Get Loss\n",
    "        thisLoss, lossForLog = self.getLoss(thisY, yHat)\n",
    "        # Backward propagate.\n",
    "        if self.modelScaler is None:\n",
    "            thisLoss.backward()\n",
    "            self.optimObj.step()\n",
    "        else:\n",
    "            self.modelScaler.scale(thisLoss).backward()\n",
    "            self.modelScaler.step(self.optimObj)\n",
    "            self.modelScaler.update()\n",
    "        \n",
    "        return lossForLog\n",
    "    \n",
    "    def updateMeanMeters(self, thisPhase: str, newLosses: Dict=None, newMetrics: Dict=None) -> None:\n",
    "\n",
    "        # Get mean trackers.\n",
    "        trackerObj = self.meanMeters.get(thisPhase, None)\n",
    "        if trackerObj is None: return\n",
    "\n",
    "        # Update tracker.\n",
    "        if not newLosses is None:\n",
    "            for k in newLosses: trackerObj[k] = newLosses[k]\n",
    "        if not newMetrics is None:\n",
    "            for k in newMetrics: trackerObj[k] = newMetrics[k]\n",
    "        pass\n",
    "\n",
    "    def writeModelToDisk(self, savePath: str, saveName: str):\n",
    "        # Create state dict.\n",
    "        saveDict = {\"modelParams\": self.engineModel.state_dict(), \n",
    "                    \"optimParams\": self.optimObj.state_dict(), \n",
    "                    \"schedulerParams\": self.schedulerObj.state_dict(),\n",
    "                    \"trainConfig\": self.trainConfig.copy()}\n",
    "        # Save to disk.\n",
    "        os.makedirs(savePath, exist_ok=True)\n",
    "        torch.save(saveDict, F\"{savePath}/{saveName}\")\n",
    "        pass\n",
    "    \n",
    "    def saveCheckPoint(self, epochIdx: int):\n",
    "        \n",
    "        # Get monitoring key.\n",
    "        monitorKey, lessThan = self.trainConfig[\"monitorKey\"], self.trainConfig[\"saveIfLess\"]\n",
    "        \n",
    "        # Switch to loss if monitoring metric not available.\n",
    "        if not self.meanMeters[\"Valid\"].hasKey(monitorKey): \n",
    "            print(F\"  Key {monitorKey} not found. Will be monitoring loss to save checkpoint.\")\n",
    "            monitorKey = \"totalLoss\"\n",
    "\n",
    "        # Save this epoch model.\n",
    "        self.writeModelToDisk(F\"{self.trainConfig['savePath']}/checkPoints/Epoch_{epochIdx}\", \n",
    "                              saveName=\"engineParams.pth\")\n",
    "\n",
    "        if lessThan:\n",
    "            # Skip if no improvement.\n",
    "            if (not self.trainConfig[\"currentBest\"] is None) and \\\n",
    "                self.meanMeters[\"Valid\"][monitorKey] >= self.trainConfig[\"currentBest\"]: \n",
    "                return\n",
    "            # Save model and update current best.\n",
    "            print(F\"  Lower {monitorKey} achieved. Previous Value {self.trainConfig['currentBest']}\\\n",
    ", Current Value {self.meanMeters['Valid'][monitorKey]}. Saving Model.\") \n",
    "            self.trainConfig[\"currentBest\"] = self.meanMeters[\"Valid\"][monitorKey]\n",
    "            savVal = \"{:.4f}\".format(self.meanMeters[\"Valid\"][monitorKey])\n",
    "            self.bestModel = copy.deepcopy(self.engineModel)\n",
    "            self.writeModelToDisk(F\"{self.trainConfig['savePath']}/checkPoints/{epochIdx}_{savVal}\", \n",
    "                                  saveName=\"engineParams.pth\")\n",
    "        else:\n",
    "            # Skip if no improvement.\n",
    "            if (not self.trainConfig[\"currentBest\"] is None) and \\\n",
    "                self.meanMeters[\"Valid\"][monitorKey] <= self.trainConfig[\"currentBest\"]: \n",
    "                return\n",
    "            # Save model and update current best.\n",
    "            print(F\"  Higher {monitorKey} achieved. Previous Value {self.trainConfig['currentBest']}\\\n",
    ", Current Value {self.meanMeters['Valid'][monitorKey]}. Saving Model.\")\n",
    "            self.trainConfig[\"currentBest\"] = self.meanMeters[\"Valid\"][monitorKey]\n",
    "            savVal = \"{:.4f}\".format(self.meanMeters[\"Valid\"][monitorKey])\n",
    "            self.writeModelToDisk(F\"{self.trainConfig['savePath']}/checkPoints/{epochIdx}_{savVal}\", \n",
    "                                  saveName=\"engineParams.pth\")\n",
    "\n",
    "        pass\n",
    "    \n",
    "    def verboseEpoch(self, epochIdx: int, epochLogs: Dict={}) -> None:\n",
    "        \n",
    "        # Log to display.\n",
    "        print(F\"  Epoch {epochIdx} Stats.\")\n",
    "        for k in self.meanMeters.keys():\n",
    "            print(F\"   {k} Metrics: \", end=\"\")\n",
    "            for m in self.meanMeters[k].keys: \n",
    "                print(F\"{m}:\", \"{:.4f}\".format(self.meanMeters[k][m]), end=\", \")\n",
    "            print(\"\")\n",
    "        \n",
    "        # Add column names in log csv.\n",
    "        if self.__logKeysEpoch is None:\n",
    "            lKeys = self.meanMeters[list(self.meanMeters.keys())[0]].keys + list(epochLogs.keys())\n",
    "            self.__logKeysEpoch = \"Epoch,Phase,\"\n",
    "            for s in lKeys: self.__logKeysEpoch += F\"{s},\"\n",
    "            self.__logFile[\"Epoch_Logs\"].write(F\"{self.__logKeysEpoch[:-1]}\\n\")\n",
    "            self.__logKeysEpoch = self.__logKeysEpoch[:-1].split(\",\")\n",
    "            pass\n",
    "\n",
    "        # Log to file.\n",
    "        if \"Epoch_Logs\" in self.__logFile.keys() and (not self.__logFile[\"Epoch_Logs\"] is None):\n",
    "            \n",
    "            for k in self.meanMeters.keys():\n",
    "                # Get meter.\n",
    "                thisMeter = self.meanMeters[k]\n",
    "                if thisMeter is None: continue\n",
    "                logDict: Dict = thisMeter.getAll()\n",
    "                logDict.update(epochLogs)\n",
    "\n",
    "                # Log string to file.\n",
    "                logString = F\"{epochIdx},{k},\"\n",
    "                for m in self.__logKeysEpoch: \n",
    "                    if m in [\"Epoch\", \"Phase\"]: continue\n",
    "                    if logDict.get(m, None) is None: logString += \"NaN,\"\n",
    "                    else: logString += \"{:.4f},\".format(logDict[m])  \n",
    "                self.__logFile[\"Epoch_Logs\"].write(F\"{logString[:-1]}\\n\")\n",
    "            pass\n",
    "        \n",
    "        # Log to wandb if required.\n",
    "        if not self.trainConfig[\"useWandB\"]: return\n",
    "        wandbLogs = {}\n",
    "        for k in self.meanMeters.keys(): \n",
    "          thisLogs = { F\"EpochLog_{k}_{m}\": self.meanMeters[k][m] for m in self.meanMeters[k].keys }\n",
    "          wandbLogs.update(thisLogs)\n",
    "        wandb.log(wandbLogs)\n",
    "        pass\n",
    "\n",
    "    def logAndVerbose(self, logIdx: int, thisLosses: Dict={}, thisMetrics: Dict={}, \n",
    "                      thisPhase: str=\"Test\"):\n",
    "        \n",
    "        # Print if required.\n",
    "        if self.trainConfig[\"printAfterBatch\"] > 0 and logIdx%self.trainConfig[\"printAfterBatch\"] == 0:\n",
    "            print(F\"   Batch {logIdx}\")\n",
    "            print(\"    Losses : \", end=\"\")\n",
    "            for k in thisLosses: print(F\"{k}:\", \"{:.4f}\".format(thisLosses[k]), end=\", \")\n",
    "            print(\"\\n    Metrics : \", end=\"\")\n",
    "            for k in thisMetrics: print(F\"{k}:\", \"{:.4f}\".format(thisMetrics[k]), end=\", \")\n",
    "            print()\n",
    "        \n",
    "        # Add CSV keys once.\n",
    "        if self.__logKeys is None: \n",
    "            \n",
    "            # Create log keys.\n",
    "            self.__logKeys = \"\"\n",
    "            for k in thisLosses: self.__logKeys += F\"{k},\"\n",
    "            for k in thisMetrics: self.__logKeys += F\"{k},\"\n",
    "            self.__logKeys = self.__logKeys[:-1]\n",
    "\n",
    "            # Write keys to file.\n",
    "            for fileKey, fileObj in self.__logFile.items():\n",
    "                if fileObj is None or \"Epoch_\" in fileKey: continue\n",
    "                fileObj.write(F\"{self.__logKeys}\\n\")\n",
    "            self.__logKeys = self.__logKeys.split(\",\")\n",
    "            pass\n",
    "        \n",
    "        # Log to file if required.\n",
    "        if not self.__logFile is None:\n",
    "            logMetrics = \"\"\n",
    "            for k in self.__logKeys:\n",
    "                tMetric = thisLosses.get(k, None)\n",
    "                if tMetric is None: tMetric = thisMetrics.get(k)\n",
    "                logMetrics += \"{:.4f},\".format(tMetric)\n",
    "            self.__logFile[thisPhase].write(F\"{logMetrics[:-1]}\\n\")\n",
    "        \n",
    "        # Skip if log to wandb not required.\n",
    "        if self.trainConfig[\"logAfterBatch\"] < 0 or logIdx%self.trainConfig[\"logAfterBatch\"] != 0: \n",
    "            return\n",
    "\n",
    "        # Log to WandB if required.\n",
    "        thisMetrics.update(thisLosses)\n",
    "        thisMetrics = { F\"{thisPhase}_{k}\": thisMetrics[k] for k in thisMetrics.keys() }\n",
    "        if self.trainConfig[\"useWandB\"]: wandb.log(thisMetrics)\n",
    "        pass\n",
    "    \n",
    "    # Callbacks\n",
    "    def saveResults(self, *args, **kwargs): pass\n",
    "    def beforeTrain(self, *args, **kwargs): pass\n",
    "    def afterTrain(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeEpoch(self, *args, **kwargs): pass\n",
    "    def afterEpoch(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeTrainEpoch(self, *args, **kwargs): pass\n",
    "    def afterTrainEpoch(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeBatch(self, *args, **kwargs): pass\n",
    "    def afterBatch(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeValidationEpoch(self, *args, **kwargs): pass\n",
    "    def afterValidationEpoch(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeTestingEpoch(self, *args, **kwargs): pass\n",
    "    def afterTestingEpoch(self, *args, **kwargs): pass\n",
    "\n",
    "    def beforeEvalEpoch(self, *args, **kwargs): pass\n",
    "    def afterEvalEpoch(self, *args, **kwargs): pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebe16827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer_Legacy(TrainEngine):\n",
    "\n",
    "    def __init__(self, engineModel,  projectName: str, runName: str, savePath: str=None, usageMode: str=\"Train\", torDevice: str=None, useWandb: bool=False):\n",
    "        super().__init__(engineModel, projectName, runName, savePath, usageMode, torDevice, useWandb)\n",
    "        pass\n",
    "\n",
    "    def getLoss(self, thisY: Union[List, Tuple, torch.Tensor], yHat: Union[List, Tuple, torch.Tensor]) -> Tuple[torch.Tensor, Dict]:\n",
    "        \n",
    "#         print(\"YHA IN GET LOSS\", yHat)\n",
    "\n",
    "#         yHat = yHat[0]\n",
    "#         print(\"YHA[0] IN GET LOSS\", yHat[0])\n",
    "        thisY = thisY[0].argmax(1)\n",
    "        \n",
    "        totalLoss = self.lossObj(yHat, thisY)\n",
    "        outDict = {\"totalLoss\": totalLoss.item()}\n",
    "        \n",
    "        return totalLoss, outDict\n",
    "\n",
    "    def getMetrics(self, thisY, yHat):\n",
    "        \n",
    "        \n",
    "        thisY = thisY[0].detach().argmax(1).cpu().numpy()\n",
    "        yHat = yHat.detach().softmax(1).argmax(1).cpu().numpy()\n",
    "#         print(\"GET METRIC YHAT[0]\", yHat[0])\n",
    "        \n",
    "        thisAcc = (thisY == yHat).sum() / len(yHat)\n",
    "        F1Score = f1_score(thisY, yHat, average=None).mean()\n",
    "        \n",
    "        return {\"F1_clsHead\": F1Score, \"Accuracy\": thisAcc}\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "857a3f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5000e-06.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "savePath = os.path.join(os.getcwd(), \"models\")\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "myEngine = Trainer_Legacy(model, \"QUANTIZED_AWARE_TRAINING_2\", \"raw_resnet50_1\", useWandb=False, torDevice=\"cuda\", savePath=savePath)\n",
    "# myEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0., lossObj=nn.BCEWithLogitsLoss(), nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0001, cosineCycle=5)\n",
    "myEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0.000005, lossObj=lossObj, nEpochs=EPOCHS, \n",
    "                         learningRate=0.0000015, cosineCycle=5)\n",
    "# myEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0., lossObj=None, nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0003, cosineCycle=5)\n",
    "\n",
    "\n",
    "# myEngine.prepareForTrain(engineParams=\"/opt/infilect/dev/storage2/shyam/Data/KH_USA/KSSB_PastaSauce/splitData/ModelLogs/Sigmoid_KsPs/Run_3/checkPoints/5_0.001/engineParams.pth\",\n",
    "#                          batchSize=BATCH_SIZE, weightDecay=0., lossObj=nn.BCEWithLogitsLoss(), nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0001, cosineCycle=5)\n",
    "\n",
    "myEngine.trainConfig[\"label2Idx\"], myEngine.trainConfig[\"idx2Label\"] = trainSet.label2Idx.copy(), trainSet.idx2Label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a9c32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(F\"{myEngine.trainConfig['savePath']}/label2Idx.json\", 'w') as jF: json.dump(trainSet.label2Idx, jF)\n",
    "with open(F\"{myEngine.trainConfig['savePath']}/idx2Label.json\", 'w') as jF: json.dump(trainSet.idx2Label, jF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66a1e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrSched_ = torch.optim.lr_scheduler.CosineAnnealingLR(myEngine.optimObj, 4, 0.00001)\n",
    "# lrSched_ = torch.optim.lr_scheduler.StepLR(myEngine.optimObj, last_epoch=EPOCHS, step_size=5, gamma=0.7)\n",
    "# lrSched = GradualWarmupScheduler(myEngine.optimObj, 1, 4, lrSched_)\n",
    "# myEngine.setupLRScheduler(lrSched)\n",
    "# myEngine.optimObj.param_groups[0][\"lr\"] = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e8400ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.5000e-06.\n"
     ]
    }
   ],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.StepLR(myEngine.optimObj, step_size=3, gamma=0.7)\n",
    "# lrSched = GradualWarmupScheduler(myEngine.optimObj, 1, 3, scheduler)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(myEngine.optimObj, T_max = 4, eta_min=0.00001, verbose = True)\n",
    "lrSched = GradualWarmupScheduler(myEngine.optimObj, 1, 4, scheduler)\n",
    "myEngine.setupLRScheduler(lrSched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed6689f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Epoch 0. Training Phase...\n",
      "   Learning Rate 1.875e-07\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1731, \n",
      "    Metrics : F1_clsHead: 0.3043, Accuracy: 0.4375, \n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 3.75e-07\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1679, \n",
      "    Metrics : F1_clsHead: 0.3043, Accuracy: 0.4375, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 3.75e-07\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1713, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 0 Stats.\n",
      "   Train Metrics: ForwardTime: 0.1402, BackPropTime: 1.6052, BatchTime: 1.8117, totalLoss: 0.1703, F1_clsHead: 0.3859, Accuracy: 0.5240, \n",
      "   Valid Metrics: ForwardTime: 0.0080, BatchTime: 1.5574, totalLoss: 0.1666, F1_clsHead: 0.4080, Accuracy: 0.5339, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0062, BatchTime: 1.4831, totalLoss: 0.1695, F1_clsHead: 0.3527, Accuracy: 0.5096, \n",
      "  Lower totalLoss achieved. Previous Value None, Current Value 0.16659169111933028. Saving Model.\n",
      "\n",
      " Starting Epoch 1. Training Phase...\n",
      "   Learning Rate 3.75e-07\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1678, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 7.5e-07\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1686, \n",
      "    Metrics : F1_clsHead: 0.5152, Accuracy: 0.5625, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 7.5e-07\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1690, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 1 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0092, BackPropTime: 1.6364, BatchTime: 1.7119, totalLoss: 0.1694, F1_clsHead: 0.3913, Accuracy: 0.5288, \n",
      "   Valid Metrics: ForwardTime: 0.0063, BatchTime: 1.5441, totalLoss: 0.1645, F1_clsHead: 0.4763, Accuracy: 0.5710, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0063, BatchTime: 1.4975, totalLoss: 0.1708, F1_clsHead: 0.3882, Accuracy: 0.5240, \n",
      "  Lower totalLoss achieved. Previous Value 0.16659169111933028, Current Value 0.16452373351369584. Saving Model.\n",
      "\n",
      " Starting Epoch 2. Training Phase...\n",
      "   Learning Rate 7.5e-07\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1668, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 1.125e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1596, \n",
      "    Metrics : F1_clsHead: 0.5000, Accuracy: 0.6250, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 1.125e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1710, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 2 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0093, BackPropTime: 1.6372, BatchTime: 1.7131, totalLoss: 0.1696, F1_clsHead: 0.3680, Accuracy: 0.5000, \n",
      "   Valid Metrics: ForwardTime: 0.0065, BatchTime: 1.5448, totalLoss: 0.1632, F1_clsHead: 0.4834, Accuracy: 0.5749, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0062, BatchTime: 1.5008, totalLoss: 0.1701, F1_clsHead: 0.3785, Accuracy: 0.5192, \n",
      "  Lower totalLoss achieved. Previous Value 0.16452373351369584, Current Value 0.16320614374819256. Saving Model.\n",
      "\n",
      " Starting Epoch 3. Training Phase...\n",
      "   Learning Rate 1.125e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1715, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 1.5e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1677, \n",
      "    Metrics : F1_clsHead: 0.3766, Accuracy: 0.4375, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 1.5e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1664, \n",
      "    Metrics : F1_clsHead: 0.6537, Accuracy: 0.6875, \n",
      "  Epoch 3 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0091, BackPropTime: 1.6348, BatchTime: 1.7098, totalLoss: 0.1702, F1_clsHead: 0.3383, Accuracy: 0.4952, \n",
      "   Valid Metrics: ForwardTime: 0.0063, BatchTime: 1.5460, totalLoss: 0.1624, F1_clsHead: 0.5080, Accuracy: 0.5865, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0063, BatchTime: 1.5016, totalLoss: 0.1676, F1_clsHead: 0.4105, Accuracy: 0.5385, \n",
      "  Lower totalLoss achieved. Previous Value 0.16320614374819256, Current Value 0.1623996411051069. Saving Model.\n",
      "\n",
      " Starting Epoch 4. Training Phase...\n",
      "   Learning Rate 1.5e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1657, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 1.5e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1626, \n",
      "    Metrics : F1_clsHead: 0.4182, Accuracy: 0.5000, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 1.5e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1629, \n",
      "    Metrics : F1_clsHead: 0.3043, Accuracy: 0.4375, \n",
      "  Epoch 4 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0091, BackPropTime: 1.6353, BatchTime: 1.7102, totalLoss: 0.1687, F1_clsHead: 0.3430, Accuracy: 0.5048, \n",
      "   Valid Metrics: ForwardTime: 0.0064, BatchTime: 1.5459, totalLoss: 0.1624, F1_clsHead: 0.4827, Accuracy: 0.5728, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0065, BatchTime: 1.5021, totalLoss: 0.1685, F1_clsHead: 0.3859, Accuracy: 0.5192, \n",
      "  Lower totalLoss achieved. Previous Value 0.1623996411051069, Current Value 0.16235887365681784. Saving Model.\n",
      "\n",
      " Starting Epoch 5. Training Phase...\n",
      "   Learning Rate 1.5e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1649, \n",
      "    Metrics : F1_clsHead: 0.4182, Accuracy: 0.5000, \n",
      "Adjusting learning rate of group 0 to 2.7448e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 2.7447961799571745e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1677, \n",
      "    Metrics : F1_clsHead: 0.5608, Accuracy: 0.5625, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 2.7447961799571745e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1699, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 5 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0096, BackPropTime: 1.6353, BatchTime: 1.7114, totalLoss: 0.1686, F1_clsHead: 0.3688, Accuracy: 0.5144, \n",
      "   Valid Metrics: ForwardTime: 0.0064, BatchTime: 1.5468, totalLoss: 0.1621, F1_clsHead: 0.4856, Accuracy: 0.5783, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0062, BatchTime: 1.4995, totalLoss: 0.1694, F1_clsHead: 0.4084, Accuracy: 0.5337, \n",
      "  Lower totalLoss achieved. Previous Value 0.16235887365681784, Current Value 0.1621237631355013. Saving Model.\n",
      "\n",
      " Starting Epoch 6. Training Phase...\n",
      "   Learning Rate 2.7447961799571745e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1696, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 5.7500e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 5.750000000000001e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1656, \n",
      "    Metrics : F1_clsHead: 0.4353, Accuracy: 0.4375, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 5.750000000000001e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1766, \n",
      "    Metrics : F1_clsHead: 0.3043, Accuracy: 0.4375, \n",
      "  Epoch 6 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0089, BackPropTime: 1.6342, BatchTime: 1.7090, totalLoss: 0.1674, F1_clsHead: 0.4074, Accuracy: 0.5385, \n",
      "   Valid Metrics: ForwardTime: 0.0063, BatchTime: 1.5480, totalLoss: 0.1614, F1_clsHead: 0.4593, Accuracy: 0.5643, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0064, BatchTime: 1.5018, totalLoss: 0.1676, F1_clsHead: 0.4317, Accuracy: 0.5481, \n",
      "  Lower totalLoss achieved. Previous Value 0.1621237631355013, Current Value 0.1613848918960208. Saving Model.\n",
      "\n",
      " Starting Epoch 7. Training Phase...\n",
      "   Learning Rate 5.750000000000001e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1633, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 8.7552e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1609, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1644, \n",
      "    Metrics : F1_clsHead: 0.5636, Accuracy: 0.6250, \n",
      "  Epoch 7 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0091, BackPropTime: 1.6354, BatchTime: 1.7109, totalLoss: 0.1654, F1_clsHead: 0.3987, Accuracy: 0.5288, \n",
      "   Valid Metrics: ForwardTime: 0.0064, BatchTime: 1.5468, totalLoss: 0.1594, F1_clsHead: 0.4768, Accuracy: 0.5726, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0066, BatchTime: 1.5019, totalLoss: 0.1654, F1_clsHead: 0.3733, Accuracy: 0.5096, \n",
      "  Lower totalLoss achieved. Previous Value 0.1613848918960208, Current Value 0.15940361789294652. Saving Model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting Epoch 8. Training Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1706, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 1e-05\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1598, \n",
      "    Metrics : F1_clsHead: 0.3766, Accuracy: 0.4375, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 1e-05\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1575, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "  Epoch 8 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0096, BackPropTime: 1.6381, BatchTime: 1.7146, totalLoss: 0.1637, F1_clsHead: 0.3794, Accuracy: 0.5192, \n",
      "   Valid Metrics: ForwardTime: 0.0064, BatchTime: 1.5458, totalLoss: 0.1571, F1_clsHead: 0.4840, Accuracy: 0.5792, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0066, BatchTime: 1.5016, totalLoss: 0.1633, F1_clsHead: 0.3955, Accuracy: 0.5288, \n",
      "  Lower totalLoss achieved. Previous Value 0.15940361789294652, Current Value 0.1571065733830134. Saving Model.\n",
      "\n",
      " Starting Epoch 9. Training Phase...\n",
      "   Learning Rate 1e-05\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1562, \n",
      "    Metrics : F1_clsHead: 0.5636, Accuracy: 0.6250, \n",
      "Adjusting learning rate of group 0 to 8.7552e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1484, \n",
      "    Metrics : F1_clsHead: 0.6135, Accuracy: 0.6875, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1586, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 9 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0098, BackPropTime: 1.6373, BatchTime: 1.7139, totalLoss: 0.1620, F1_clsHead: 0.3866, Accuracy: 0.5240, \n",
      "   Valid Metrics: ForwardTime: 0.0066, BatchTime: 1.5464, totalLoss: 0.1544, F1_clsHead: 0.5332, Accuracy: 0.6126, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0068, BatchTime: 1.5017, totalLoss: 0.1598, F1_clsHead: 0.4236, Accuracy: 0.5433, \n",
      "  Lower totalLoss achieved. Previous Value 0.1571065733830134, Current Value 0.15440954764684042. Saving Model.\n",
      "\n",
      " Starting Epoch 10. Training Phase...\n",
      "   Learning Rate 8.755203820042827e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1607, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "Adjusting learning rate of group 0 to 5.7500e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 5.7499999999999975e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1576, \n",
      "    Metrics : F1_clsHead: 0.2727, Accuracy: 0.3750, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 5.7499999999999975e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1543, \n",
      "    Metrics : F1_clsHead: 0.6537, Accuracy: 0.6875, \n",
      "  Epoch 10 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0097, BackPropTime: 1.6342, BatchTime: 1.7109, totalLoss: 0.1583, F1_clsHead: 0.3891, Accuracy: 0.5240, \n",
      "   Valid Metrics: ForwardTime: 0.0066, BatchTime: 1.5473, totalLoss: 0.1519, F1_clsHead: 0.5421, Accuracy: 0.6106, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0067, BatchTime: 1.5009, totalLoss: 0.1584, F1_clsHead: 0.4099, Accuracy: 0.5337, \n",
      "  Lower totalLoss achieved. Previous Value 0.15440954764684042, Current Value 0.15189557345140547. Saving Model.\n",
      "\n",
      " Starting Epoch 11. Training Phase...\n",
      "   Learning Rate 5.7499999999999975e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1576, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 2.7448e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 2.744796179957167e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1551, \n",
      "    Metrics : F1_clsHead: 0.5152, Accuracy: 0.5625, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 2.744796179957167e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1590, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "  Epoch 11 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0099, BackPropTime: 1.6343, BatchTime: 1.7112, totalLoss: 0.1576, F1_clsHead: 0.3875, Accuracy: 0.5240, \n",
      "   Valid Metrics: ForwardTime: 0.0069, BatchTime: 1.5471, totalLoss: 0.1512, F1_clsHead: 0.5387, Accuracy: 0.6126, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0069, BatchTime: 1.5039, totalLoss: 0.1565, F1_clsHead: 0.4195, Accuracy: 0.5385, \n",
      "  Lower totalLoss achieved. Previous Value 0.15189557345140547, Current Value 0.1511858935867037. Saving Model.\n",
      "\n",
      " Starting Epoch 12. Training Phase...\n",
      "   Learning Rate 2.744796179957167e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1570, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 1.5000e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 1.4999999999999924e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1478, \n",
      "    Metrics : F1_clsHead: 0.6537, Accuracy: 0.6875, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 1.4999999999999924e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1597, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "  Epoch 12 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0100, BackPropTime: 1.6362, BatchTime: 1.7138, totalLoss: 0.1552, F1_clsHead: 0.4583, Accuracy: 0.5673, \n",
      "   Valid Metrics: ForwardTime: 0.0067, BatchTime: 1.5456, totalLoss: 0.1504, F1_clsHead: 0.5323, Accuracy: 0.6147, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0073, BatchTime: 1.5042, totalLoss: 0.1559, F1_clsHead: 0.4402, Accuracy: 0.5529, \n",
      "  Lower totalLoss achieved. Previous Value 0.1511858935867037, Current Value 0.15041387719767435. Saving Model.\n",
      "\n",
      " Starting Epoch 13. Training Phase...\n",
      "   Learning Rate 1.4999999999999924e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1571, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "Adjusting learning rate of group 0 to 2.7448e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 2.744796179957166e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1531, \n",
      "    Metrics : F1_clsHead: 0.4182, Accuracy: 0.5000, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 2.744796179957166e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1523, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "  Epoch 13 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0101, BackPropTime: 1.6339, BatchTime: 1.7111, totalLoss: 0.1557, F1_clsHead: 0.4036, Accuracy: 0.5337, \n",
      "   Valid Metrics: ForwardTime: 0.0069, BatchTime: 1.5481, totalLoss: 0.1503, F1_clsHead: 0.5265, Accuracy: 0.6060, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0069, BatchTime: 1.5029, totalLoss: 0.1552, F1_clsHead: 0.4510, Accuracy: 0.5577, \n",
      "  Lower totalLoss achieved. Previous Value 0.15041387719767435, Current Value 0.15028211758250282. Saving Model.\n",
      "\n",
      " Starting Epoch 14. Training Phase...\n",
      "   Learning Rate 2.744796179957166e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1532, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "Adjusting learning rate of group 0 to 5.7500e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 5.749999999999995e-06\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1405, \n",
      "    Metrics : F1_clsHead: 0.7257, Accuracy: 0.8125, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 5.749999999999995e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1533, \n",
      "    Metrics : F1_clsHead: 0.4589, Accuracy: 0.5625, \n",
      "  Epoch 14 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0098, BackPropTime: 1.6370, BatchTime: 1.7139, totalLoss: 0.1542, F1_clsHead: 0.4005, Accuracy: 0.5240, \n",
      "   Valid Metrics: ForwardTime: 0.0069, BatchTime: 1.5486, totalLoss: 0.1491, F1_clsHead: 0.5677, Accuracy: 0.6319, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0068, BatchTime: 1.5026, totalLoss: 0.1547, F1_clsHead: 0.4068, Accuracy: 0.5337, \n",
      "  Lower totalLoss achieved. Previous Value 0.15028211758250282, Current Value 0.14914445720967792. Saving Model.\n",
      "\n",
      " Starting Epoch 15. Training Phase...\n",
      "   Learning Rate 5.749999999999995e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1513, \n",
      "    Metrics : F1_clsHead: 0.3333, Accuracy: 0.5000, \n",
      "Adjusting learning rate of group 0 to 8.7552e-06.\n",
      "\n",
      "  Starting Validation Phase...\n",
      "   Learning Rate 8.755203820042822e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1396, \n",
      "    Metrics : F1_clsHead: 0.7949, Accuracy: 0.8750, \n",
      "\n",
      "  Starting Evaluation Phase...\n",
      "   Learning Rate 8.755203820042822e-06\n",
      " Shuffling indices...Done.\n",
      "   Batch 0\n",
      "    Losses : totalLoss: 0.1534, \n",
      "    Metrics : F1_clsHead: 0.5636, Accuracy: 0.6250, \n",
      "  Epoch 15 Stats.\n",
      "   Train Metrics: ForwardTime: 0.0100, BackPropTime: 1.6331, BatchTime: 1.7104, totalLoss: 0.1545, F1_clsHead: 0.3794, Accuracy: 0.5192, \n",
      "   Valid Metrics: ForwardTime: 0.0069, BatchTime: 1.5494, totalLoss: 0.1482, F1_clsHead: 0.5816, Accuracy: 0.6364, \n",
      "   Test Metrics: \n",
      "   Eval Metrics: ForwardTime: 0.0069, BatchTime: 1.5013, totalLoss: 0.1536, F1_clsHead: 0.4905, Accuracy: 0.5769, \n",
      "  Lower totalLoss achieved. Previous Value 0.14914445720967792, Current Value 0.148232672895704. Saving Model.\n"
     ]
    }
   ],
   "source": [
    "Engine.startTraining(trainloader1, testloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9516e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e22df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myEngine.writeModelToDisk(F\"{myEngine.trainConfig['savePath']}/checkPoints/\", \"FinalParams.pth\")\n",
    "fPath = F\"{myEngine.trainConfig['savePath']}/checkPoints/FinalParams.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e315312",
   "metadata": {},
   "outputs": [],
   "source": [
    "fPath = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING_1/raw_resnet50_1/checkPoints/Epoch_10/engineParams.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_filepath, device):\n",
    "    model_skeleton = torch.load(model_filepath, device)\n",
    "\n",
    "    model.load_state_dict(model_skeleton[\"modelParams\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7046006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_model_resnet50 = load_model(model = model, model_filepath = fPath, device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405f701",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_model_resnet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988fa8b",
   "metadata": {},
   "source": [
    "x = [[\"backBone.conv1\", \"backBone.bn1\", \"backBone.relu\"],\n",
    "     [\"backBone.layer1.0.conv1\", \"backBone.layer1.0.bn1\"], [\"backBone.layer1.0.conv2\", \"backBone.layer1.0.bn2\"], [\"backBone.layer1.0.conv3\", \"backBone.layer1.0.bn3\", \"backBone.layer1.0.relu\"], [\"backBone.layer1.0.downsample.0\", \"backBone.layer1.0.downsample.1\"], [\"backBone.layer1.1.conv1\", \"backBone.layer1.1.bn1\"], [\"backBone.layer1.1.conv2\", \"backBone.layer1.1.bn2\"], [\"backBone.layer1.1.conv3\", \"backBone.layer1.1.bn3\", \"backBone.layer1.1.relu\"], [\"backBone.layer1.2.conv1\", \"backBone.layer1.2.bn1\"], [\"backBone.layer1.2.conv2\", \"backBone.layer1.2.bn2\"], [\"backBone.layer1.2.conv3\", \"backBone.layer1.2.bn3\", \"backBone.layer1.2.relu\"],\n",
    "     [\"backBone.layer2.0.conv1\", \"backBone.layer2.0.bn1\"], [\"backBone.layer2.0.conv2\", \"backBone.layer2.0.bn2\"], [\"backBone.layer2.0.conv3\", \"backBone.layer2.0.bn3\", \"backBone.layer2.0.relu\"], [\"backBone.layer2.0.downsample.0\", \"backBone.layer2.0.downsample.1\"], [\"backBone.layer2.1.conv1\", \"backBone.layer2.1.bn1\"], [\"backBone.layer2.1.conv2\", \"backBone.layer2.1.bn2\"], [\"backBone.layer2.1.conv3\", \"backBone.layer2.1.bn3\", \"backBone.layer2.1.relu\"], [\"backBone.layer2.2.conv1\", \"backBone.layer2.2.bn1\"], [\"backBone.layer2.2.conv2\", \"backBone.layer2.2.bn2\"], [\"backBone.layer2.2.conv3\", \"backBone.layer2.2.bn3\", \"backBone.layer2.2.relu\"], [\"backBone.layer2.3.conv1\", \"backBone.layer2.3.bn1\"], [\"backBone.layer2.3.conv2\", \"backBone.layer2.3.bn2\"], [\"backBone.layer2.3.conv3\", \"backBone.layer2.3.bn3\", \"backBone.layer2.3.relu\"],\n",
    "     [\"backBone.layer3.0.conv1\", \"backBone.layer3.0.bn1\"], [\"backBone.layer3.0.conv2\", \"backBone.layer3.0.bn2\"], [\"backBone.layer3.0.conv3\", \"backBone.layer3.0.bn3\", \"backBone.layer3.0.relu\"], [\"backBone.layer3.0.downsample.0\", \"backBone.layer3.0.downsample.1\"], [\"backBone.layer3.1.conv1\", \"backBone.layer3.1.bn1\"], [\"backBone.layer3.1.conv2\", \"backBone.layer3.1.bn2\"], [\"backBone.layer3.1.conv3\", \"backBone.layer3.1.bn3\", \"backBone.layer3.1.relu\"], [\"backBone.layer3.2.conv1\", \"backBone.layer3.2.bn1\"], [\"backBone.layer3.2.conv2\", \"backBone.layer3.2.bn2\"], [\"backBone.layer3.2.conv3\", \"backBone.layer3.2.bn3\", \"backBone.layer3.2.relu\"], [\"backBone.layer3.3.conv1\", \"backBone.layer3.3.bn1\"], [\"backBone.layer3.3.conv2\", \"backBone.layer3.3.bn2\"], [\"backBone.layer3.3.conv3\", \"backBone.layer3.3.bn3\", \"backBone.layer3.3.relu\"],[\"backBone.layer3.4.conv1\", \"backBone.layer3.4.bn1\"], [\"backBone.layer3.4.conv2\", \"backBone.layer3.4.bn2\"], [\"backBone.layer3.4.conv3\", \"backBone.layer3.4.bn3\", \"backBone.layer3.4.relu\"],[\"backBone.layer3.5.conv1\", \"backBone.layer3.5.bn1\"], [\"backBone.layer3.5.conv2\", \"backBone.layer3.5.bn2\"], [\"backBone.layer3.5.conv3\", \"backBone.layer3.5.bn3\", \"backBone.layer3.5.relu\"],\n",
    "     [\"backBone.layer4.0.conv1\", \"backBone.layer4.0.bn1\"], [\"backBone.layer4.0.conv2\", \"backBone.layer4.0.bn2\"], [\"backBone.layer4.0.conv3\", \"backBone.layer4.0.bn3\", \"backBone.layer4.0.relu\"], [\"backBone.layer4.0.downsample.0\", \"backBone.layer4.0.downsample.1\"], [\"backBone.layer4.1.conv1\", \"backBone.layer4.1.bn1\"], [\"backBone.layer4.1.conv2\", \"backBone.layer4.1.bn2\"], [\"backBone.layer4.1.conv3\", \"backBone.layer4.1.bn3\", \"backBone.layer4.1.relu\"], [\"backBone.layer4.2.conv1\", \"backBone.layer4.2.bn1\"], [\"backBone.layer4.2.conv2\", \"backBone.layer4.2.bn2\"], [\"backBone.layer4.2.conv3\", \"backBone.layer4.2.bn3\", \"backBone.layer4.2.relu\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c045291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = [[\"conv1\", \"bn1\", \"relu\"],\n",
    "     [\"layer1.0.conv1\", \"layer1.0.bn1\"], [\"layer1.0.conv2\", \"layer1.0.bn2\"], [\"layer1.0.conv3\", \"layer1.0.bn3\", \"layer1.0.relu\"], [\"layer1.0.downsample.0\", \"layer1.0.downsample.1\"], [\"layer1.1.conv1\", \"layer1.1.bn1\"], [\"layer1.1.conv2\", \"layer1.1.bn2\"], [\"layer1.1.conv3\", \"layer1.1.bn3\", \"layer1.1.relu\"], [\"layer1.2.conv1\", \"layer1.2.bn1\"], [\"layer1.2.conv2\", \"layer1.2.bn2\"], [\"layer1.2.conv3\", \"layer1.2.bn3\", \"layer1.2.relu\"],\n",
    "     [\"layer2.0.conv1\", \"layer2.0.bn1\"], [\"layer2.0.conv2\", \"layer2.0.bn2\"], [\"layer2.0.conv3\", \"layer2.0.bn3\", \"layer2.0.relu\"], [\"layer2.0.downsample.0\", \"layer2.0.downsample.1\"], [\"layer2.1.conv1\", \"layer2.1.bn1\"], [\"layer2.1.conv2\", \"layer2.1.bn2\"], [\"layer2.1.conv3\", \"layer2.1.bn3\", \"layer2.1.relu\"], [\"layer2.2.conv1\", \"layer2.2.bn1\"], [\"layer2.2.conv2\", \"layer2.2.bn2\"], [\"layer2.2.conv3\", \"layer2.2.bn3\", \"layer2.2.relu\"], [\"layer2.3.conv1\", \"layer2.3.bn1\"], [\"layer2.3.conv2\", \"layer2.3.bn2\"], [\"layer2.3.conv3\", \"layer2.3.bn3\", \"layer2.3.relu\"],\n",
    "     [\"layer3.0.conv1\", \"layer3.0.bn1\"], [\"layer3.0.conv2\", \"layer3.0.bn2\"], [\"layer3.0.conv3\", \"layer3.0.bn3\", \"layer3.0.relu\"], [\"layer3.0.downsample.0\", \"layer3.0.downsample.1\"], [\"layer3.1.conv1\", \"layer3.1.bn1\"], [\"layer3.1.conv2\", \"layer3.1.bn2\"], [\"layer3.1.conv3\", \"layer3.1.bn3\", \"layer3.1.relu\"], [\"layer3.2.conv1\", \"layer3.2.bn1\"], [\"layer3.2.conv2\", \"layer3.2.bn2\"], [\"layer3.2.conv3\", \"layer3.2.bn3\", \"layer3.2.relu\"], [\"layer3.3.conv1\", \"layer3.3.bn1\"], [\"layer3.3.conv2\", \"layer3.3.bn2\"], [\"layer3.3.conv3\", \"layer3.3.bn3\", \"layer3.3.relu\"],[\"layer3.4.conv1\", \"layer3.4.bn1\"], [\"layer3.4.conv2\", \"layer3.4.bn2\"], [\"layer3.4.conv3\", \"layer3.4.bn3\", \"layer3.4.relu\"],[\"layer3.5.conv1\", \"layer3.5.bn1\"], [\"layer3.5.conv2\", \"layer3.5.bn2\"], [\"layer3.5.conv3\", \"layer3.5.bn3\", \"layer3.5.relu\"],\n",
    "     [\"layer4.0.conv1\", \"layer4.0.bn1\"], [\"layer4.0.conv2\", \"layer4.0.bn2\"], [\"layer4.0.conv3\", \"layer4.0.bn3\", \"layer4.0.relu\"], [\"layer4.0.downsample.0\", \"layer4.0.downsample.1\"], [\"layer4.1.conv1\", \"layer4.1.bn1\"], [\"layer4.1.conv2\", \"layer4.1.bn2\"], [\"layer4.1.conv3\", \"layer4.1.bn3\", \"layer4.1.relu\"], [\"layer4.2.conv1\", \"layer4.2.bn1\"], [\"layer4.2.conv2\", \"layer4.2.bn2\"], [\"layer4.2.conv3\", \"layer4.2.bn3\", \"layer4.2.relu\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aef0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e8b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizedModelTrainingPrerequsite(model, nestedList, device):\n",
    "    #loding the model on cpu device cause cuda doesnt support quantization\n",
    "    model.to(device)\n",
    "\n",
    "    #creating a copy of model which will be used for quantization\n",
    "    fused_model = copy.deepcopy(model)\n",
    "\n",
    "    # putting model on training model otherwise QAT won't work\n",
    "    fused_model.train()\n",
    "\n",
    "    # Fuse the model in place rather manually.\n",
    "    fused_model = torch.ao.quantization.fuse_modules_qat(fused_model, nestedList, inplace=False)\n",
    "    return fused_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model_resnet50 = quantizedModelTrainingPrerequsite(model = raw_model_resnet50, nestedList = x_raw, device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b08290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model for quantization aware training. This inserts observers in\n",
    "# the model that will observe activation tensors during calibration.\n",
    "# torch.distributed.init_process_group(backend='nccl', world_size = 1, rank=1)\n",
    "quantized_model = QuantizedModel(model_fp32 = fused_model_resnet50)\n",
    "# quantized_model = nn.parallel.DistributedDataParallel(quantized_model)\n",
    "\n",
    "# Using un-fused model will fail.\n",
    "# Because there is no quantized layer implementation for a single batch normalization layer.\n",
    "# quantized_model = QuantizedResNet18(model_fp32=model)\n",
    "# Select quantization schemes from\n",
    "# https://pytorch.org/docs/stable/quantization-support.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f273ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1754771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainingWithQuantization(model):\n",
    "    quantization_config = torch.ao.quantization.get_default_qat_qconfig(\"x86\", version=0)\n",
    "    # Custom quantization configurations\n",
    "    # quantization_config = torch.quantization.default_qconfig\n",
    "    # quantization_config = torch.quantization.QConfig(activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n",
    "\n",
    "    model.qconfig = quantization_config\n",
    "\n",
    "    # Print quantization configurations\n",
    "    #print(quantized_model.qconfig)\n",
    "\n",
    "    # https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare_qat\n",
    "    quantized_model = torch.ao.quantization.prepare_qat(model, inplace=False)\n",
    "\n",
    "    return quantized_model\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd534e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_model = prepareTrainingWithQuantization(model = quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb1dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db7412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083de86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = os.path.join(os.getcwd(), \"models\")\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "# lossObject = nn.CrossEntropyLoss()\n",
    "lossObj = FocalLossMultiClass()\n",
    "myQuantEngine = Trainer_Legacy(quant_model, \"QUANTIZED_AWARE_TRAINING_1\", \"quant_resnet50_1\", useWandb=False, torDevice=\"cpu\", savePath=savePath)\n",
    "# myEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0., lossObj=nn.BCEWithLogitsLoss(), nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0001, cosineCycle=5)\n",
    "myQuantEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0.000002, lossObj=lossObj, nEpochs=EPOCHS, \n",
    "                         learningRate=0.000015, cosineCycle=5)\n",
    "# myEngine.prepareForTrain(batchSize=BATCH_SIZE, weightDecay=0., lossObj=None, nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0003, cosineCycle=5)\n",
    "\n",
    "\n",
    "# myEngine.prepareForTrain(engineParams=\"/opt/infilect/dev/storage2/shyam/Data/KH_USA/KSSB_PastaSauce/splitData/ModelLogs/Sigmoid_KsPs/Run_3/checkPoints/5_0.001/engineParams.pth\",\n",
    "#                          batchSize=BATCH_SIZE, weightDecay=0., lossObj=nn.BCEWithLogitsLoss(), nEpochs=EPOCHS, \n",
    "#                          learningRate=0.0001, cosineCycle=5)\n",
    "\n",
    "myQuantEngine.trainConfig[\"label2Idx\"], myQuantEngine.trainConfig[\"idx2Label\"] = trainSet.label2Idx.copy(), trainSet.idx2Label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e28403",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(F\"{myQuantEngine.trainConfig['savePath']}/label2Idx.json\", 'w') as jF: json.dump(trainSet.label2Idx, jF)\n",
    "with open(F\"{myQuantEngine.trainConfig['savePath']}/idx2Label.json\", 'w') as jF: json.dump(trainSet.idx2Label, jF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(myQuantEngine.optimObj, T_max = 1, eta_min=0.00001, verbose = True)\n",
    "lrSched = GradualWarmupScheduler(myQuantEngine.optimObj, 1, 4, scheduler)\n",
    "myQuantEngine.setupLRScheduler(lrSched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a03d36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myQuantEngine.startTraining(trainloader1, testloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029df8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "myQuantEngine.writeModelToDisk(F\"{myQuantEngine.trainConfig['savePath']}/checkPoints/\", \"FinalParams.pth\")\n",
    "fPath = F\"{myQuantEngine.trainConfig['savePath']}/checkPoints/FinalParams.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = myQuantEngine.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8557769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725ce2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath_x = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING/quant_resnet50_2/checkPoints/Epoch_4/engineParams.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineParams1 = torch.load(modelPath_x, map_location=\"cuda\")\n",
    "modelParams1 = engineParams1[\"modelParams\"]\n",
    "quant_model.load_state_dict(engineParams1[\"modelParams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794deba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to('cpu')\n",
    "x.eval()\n",
    "model_int8 = torch.ao.quantization.convert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c954176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1677059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_int8\n",
    "model_dir = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING_1/quant_model\"\n",
    "model_filename = \"model_int8_3.pth\"\n",
    "save_torchscript_model(model, model_dir, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7408beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torchscript_model(model_filepath, device):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5ecebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e9c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa62149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff5df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model_int8, F\"{myQuantEngine.trainConfig['savePath']}/checkPoints/MODEL_INT8.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d968942",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79047243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List, Tuple, Dict\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score, multilabel_confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as torchModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc52873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "class ClassHead(nn.Module):\n",
    "    def __init__(self, inpUnits=1280, opOut=2):\n",
    "        super().__init__()\n",
    "        self.seqBlock_0 = nn.Sequential(torch.nn.Dropout(0.3), torch.nn.Linear(inpUnits, opOut))\n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor: return self.seqBlock_0(inpX)\n",
    "    pass\n",
    "class BasicModel(nn.Module):\n",
    "    def __init__(self, model_name: str, nClasses: int):\n",
    "        super().__init__()\n",
    "        self.backBone = models.get_model(model_name, weights = \"DEFAULT\")\n",
    "        # self.backBone = torchModels.resnet50(weights=torchModels.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.backBone.fc = nn.Identity()\n",
    "        self.classHead = ClassHead(2048, nClasses)\n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor:\n",
    "        embX = self.backBone(inpX)\n",
    "        out = self.classHead(embX)\n",
    "        return out\n",
    "\n",
    "class QuantizedModel(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedModel, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "    def forward(self, inpX: torch.Tensor) -> torch.Tensor:\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        embX = self.quant(inpX)\n",
    "        quantX = self.model_fp32(embX)\n",
    "        out_quant = self.dequant(quantX)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "#         deQuantX = self.dequant(quantX)\n",
    "        return out_quant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePred(savePath: str, gtName: str, prName: str, savImg: str, imgIdx: int):\n",
    "    os.makedirs(F\"{savePath}/{gtName}/{prName}\", exist_ok=True)\n",
    "    img = Image.open(savImg)\n",
    "    img.save(F\"{savePath}/{gtName}/{prName}/{imgIdx}.png\")\n",
    "    pass\n",
    "\n",
    "@torch.no_grad()\n",
    "def onEval(thisModel, evalLoader):\n",
    "    predVals = { k:[] for k in [50, 60, 70, 80, 90, 95] }\n",
    "    gtVals = []\n",
    "    with torch.no_grad():\n",
    "        for i, s in enumerate(evalLoader):\n",
    "            print(F\" Working on image {i+1} of {len(evalLoader)}\")\n",
    "            \n",
    "            tX, tY = torch.unsqueeze(s[0][0], 0).to(torDevice), s[1][0].cpu().numpy()\n",
    "            yH = thisModel(tX)[0].detach().sigmoid().cpu().numpy()\n",
    "            if tY.sum() == 0: gtVals.append(-1)\n",
    "            else: gtVals.append(np.argmax(tY))\n",
    "            # gtVals.append(-1)\n",
    "            \n",
    "            yhMax = yH.max()\n",
    "            for k in predVals.keys(): predVals[k].append(-1)\n",
    "            if yhMax < 0.5: continue\n",
    "            \n",
    "            if yhMax > 0.5: predVals[50][-1] = (np.argmax(yH))\n",
    "            if yhMax > 0.6: predVals[60][-1] = (np.argmax(yH))\n",
    "            if yhMax > 0.7: predVals[70][-1] = (np.argmax(yH))\n",
    "            if yhMax > 0.8: predVals[80][-1] = (np.argmax(yH))\n",
    "            if yhMax > 0.9: predVals[90][-1] = (np.argmax(yH))\n",
    "            if yhMax > 0.95: predVals[95][-1] = (np.argmax(yH))\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    return gtVals, predVals\n",
    "\n",
    "@torch.no_grad()\n",
    "def onEvalOld(thisModel, evalLoader, idxToLabel, savePath=None):#, validLabels, newLabelIdxMap):\n",
    "    \n",
    "    predVals, gtVals = {50:[]}, []\n",
    "    thisModel.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, s in enumerate(evalLoader):\n",
    "            print(F\" Working on image {i+1} of {len(evalLoader)}\")\n",
    "#             print(evalLoader.dataList[i][1])\n",
    "            \n",
    "            tX, tY = torch.unsqueeze(s[0][0], 0).to(\"cpu\"), s[1][0].cpu().numpy()\n",
    "            yH = thisModel(tX).detach().softmax(dim=1).cpu().numpy().argmax(1)\n",
    "#             print(yH)\n",
    "            \n",
    "            if tY.sum() == 0: \n",
    "                gtVals.append(-1)\n",
    "            else: \n",
    "                gtVals.append(np.argmax(tY))\n",
    "                \n",
    "            predVals[50].append(yH)\n",
    "            \n",
    "            if savePath is None: continue\n",
    "            savePred(savePath, idx2Label[gtVals[-1]], idx2Label[int(yH)], evalLoader.dataList[i][1], i)\n",
    "        pass\n",
    "    return gtVals, predVals\n",
    "\n",
    "@torch.no_grad()\n",
    "def onEvalSigMax(thisModel, evalLoader, thisSetMap, idxToLabel, labelToIdx, valLabelNames, valLabelIdx):\n",
    "    \n",
    "    modelOut, predVals, gtVals = [], {50:[]}, []\n",
    "    with torch.no_grad():\n",
    "        for i, s in enumerate(evalLoader):\n",
    "            print(F\" Working on image {i+1} of {len(evalLoader)}\")\n",
    "            \n",
    "            tX, tY = torch.unsqueeze(s[0][0], 0).to(torDevice), np.argmax(s[1][0].cpu().numpy())\n",
    "            yHat = thisModel(tX).detach()\n",
    "            modelOut.append(yHat.cpu())\n",
    "            yH = yHat.softmax(dim=1).cpu().numpy().argmax(1)[0]\n",
    "            \n",
    "            if thisSetMap[tY] in valLabelNames: gtVals.append(labelToIdx[thisSetMap[tY]])\n",
    "            else: gtVals.append(-1)\n",
    "            \n",
    "            # if yHat[0].sigmoid().cpu().numpy()[valLabelIdx].max() < 0.4: predVals[50].append(-1)\n",
    "            if idxToLabel[yH] in valLabelNames: predVals[50].append(yH)\n",
    "            else: predVals[50].append(-1)\n",
    "        pass\n",
    "    return gtVals, predVals, modelOut\n",
    "\n",
    "@torch.no_grad()\n",
    "def onEvalGroup(thisModel, evalLoader, idxToLabel, labelsGroup):#, validLabels, newLabelIdxMap):\n",
    "    \n",
    "    predVals, gtVals = {50:[]}, []\n",
    "    qcCheck = [set(cg) for cg in labelsGroup]\n",
    "    with torch.no_grad():\n",
    "        for i, s in enumerate(evalLoader):\n",
    "            print(F\" Working on image {i+1} of {len(evalLoader)}\")\n",
    "            \n",
    "            tX, tY = torch.unsqueeze(s[0][0], 0).to(torDevice), s[1][0].cpu().numpy()\n",
    "            yH = thisModel(tX)[0].detach()# .softmax(0).cpu().numpy().argmax()\n",
    "\n",
    "            if tY.sum() == 0: gtVals.append(-1)\n",
    "            else: gtVals.append(np.argmax(tY))\n",
    "            \n",
    "            for i, cg in enumerate(labelsGroup):\n",
    "                if not idxToLabel[gtVals[-1]] in qcCheck[i]: continue\n",
    "                finPred = torch.tensor([yH[testSet.label2Idx[l]] for l in cg]).softmax(0).numpy().argmax()\n",
    "                finPred = testSet.label2Idx[cg[finPred]]\n",
    "            predVals[50].append(finPred)\n",
    "        pass\n",
    "    return gtVals, predVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec923580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetricJson(gTs, mPs, idx2Label):\n",
    "    \n",
    "    outDict, aggMetrics = {}, {k:{} for k in mPs}\n",
    "    allClasses = np.unique(gTs)\n",
    "    \n",
    "    for cI in allClasses:\n",
    "        outDict[idx2Label[cI+1]] = {}\n",
    "        for k in mPs:\n",
    "            outDict[idx2Label[cI+1]][k] = {}\n",
    "            tPrec = np.nan_to_num((gTs[mPs[k] == cI] == cI).sum() / (mPs[k] == cI).sum())\n",
    "            tRcall = np.nan_to_num((mPs[k][gTs == cI] == cI).sum() / (gTs == cI).sum())\n",
    "            outDict[idx2Label[cI+1]][k][\"F1Score\"] = np.nan_to_num(2 * ((tPrec*tRcall) / (tPrec+tRcall)))\n",
    "            outDict[idx2Label[cI+1]][k][\"precisionVal\"] = tPrec\n",
    "            outDict[idx2Label[cI+1]][k][\"recallVal\"] = tRcall\n",
    "            \n",
    "            aggMetrics[k][\"precisionVal\"] = aggMetrics[k].get(\"precisionVal\", 0) + tPrec\n",
    "            aggMetrics[k][\"recallVal\"] = aggMetrics[k].get(\"recallVal\", 0) + tRcall\n",
    "            aggMetrics[k][\"F1Score\"] = aggMetrics[k].get(\"F1Score\", 0) + outDict[idx2Label[cI+1]][k][\"F1Score\"]\n",
    "            pass\n",
    "    \n",
    "    for k in mPs.keys():\n",
    "        aggMetrics[k][\"Accuracy\"] = (gTs == mPs[k]).sum() / len(gTs)\n",
    "        aggMetrics[k][\"BalAccuracy\"] = balanced_accuracy_score(gTs, mPs[k])\n",
    "        \n",
    "        aggMetrics[k][\"precisionVal\"] = aggMetrics[k][\"precisionVal\"] / len(allClasses)\n",
    "        aggMetrics[k][\"recallVal\"] = aggMetrics[k][\"recallVal\"] / len(allClasses)\n",
    "        aggMetrics[k][\"F1Score\"] = aggMetrics[k][\"F1Score\"] / len(allClasses)\n",
    "        pass\n",
    "        \n",
    "    return outDict, aggMetrics\n",
    "\n",
    "def getMetricJson_Legacy(gTs, mPs, idx2Label):\n",
    "    \n",
    "    outDict, aggMetrics = {}, {k:{} for k in mPs}\n",
    "    allClasses = np.unique(gTs)\n",
    "    \n",
    "    for cI in allClasses:\n",
    "        outDict[idx2Label[cI]] = {}\n",
    "        for k in mPs:\n",
    "            outDict[idx2Label[cI]][k] = {}\n",
    "            tPrec = np.nan_to_num((gTs[mPs[k] == cI] == cI).sum() / (mPs[k] == cI).sum())\n",
    "            tRcall = np.nan_to_num((mPs[k][gTs == cI] == cI).sum() / (gTs == cI).sum())\n",
    "            outDict[idx2Label[cI]][k][\"F1Score\"] = np.nan_to_num(2 * ((tPrec*tRcall) / (tPrec+tRcall)))\n",
    "            outDict[idx2Label[cI]][k][\"precisionVal\"] = tPrec\n",
    "            outDict[idx2Label[cI]][k][\"recallVal\"] = tRcall\n",
    "            \n",
    "            aggMetrics[k][\"precisionVal\"] = aggMetrics[k].get(\"precisionVal\", 0) + tPrec\n",
    "            aggMetrics[k][\"recallVal\"] = aggMetrics[k].get(\"recallVal\", 0) + tRcall\n",
    "            aggMetrics[k][\"F1Score\"] = aggMetrics[k].get(\"F1Score\", 0) + outDict[idx2Label[cI]][k][\"F1Score\"]\n",
    "            pass\n",
    "    \n",
    "    for k in mPs.keys():\n",
    "        aggMetrics[k][\"Accuracy\"] = (gTs == mPs[k]).sum() / len(gTs)\n",
    "        aggMetrics[k][\"BalAccuracy\"] = balanced_accuracy_score(gTs, mPs[k])\n",
    "        \n",
    "        aggMetrics[k][\"precisionVal\"] = aggMetrics[k][\"precisionVal\"] / len(allClasses)\n",
    "        aggMetrics[k][\"recallVal\"] = aggMetrics[k][\"recallVal\"] / len(allClasses)\n",
    "        aggMetrics[k][\"F1Score\"] = aggMetrics[k][\"F1Score\"] / len(allClasses)\n",
    "        pass\n",
    "        \n",
    "    return outDict, aggMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d52cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "class ClassificationMetrics:\n",
    "    \"\"\"Classification metrics class. Create an object of this class\n",
    "    to individually track metric of different models/datasets/runs.\n",
    "    \"\"\"\n",
    "    def __init__(self, name, classes):\n",
    "        \"\"\"Initialise an object of this class.\n",
    "        \n",
    "        Args:\n",
    "            name (str): A name given to a metrics object. Currently not being used for anything but\n",
    "            could be used for uniquely identify a metrics object by name\n",
    "            classes (list): A list of names of classes.\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.classes = sorted(classes)\n",
    "        # Check if all elements in the classes list is unique.\n",
    "        assert len(set(self.classes)) == len(classes)\n",
    "\n",
    "        self.num_classes = len(classes)\n",
    "        self.class2int = {c:i for i,c in enumerate(self.classes)}\n",
    "        self.int2class = {self.class2int[c]:c for c in self.class2int}\n",
    "        # Initialise the confusion matrix with all zeros\n",
    "        self.classification_confusion_matrix = np.zeros((len(self.classes),len(self.classes)))\n",
    "\n",
    "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        self.fontScale = 0.8\n",
    "        self.fontColor = (255, 0, 0)\n",
    "        self.lineType = 2\n",
    "\n",
    "    def create_cell(self,color_value,text,shape):\n",
    "        \"\"\"Create a cell image to be a part of confusion matrix image. This is just a square\n",
    "        patch of some given size with a given color value and the text written in the center\n",
    "        \n",
    "        Args:\n",
    "            color_value (str): Background Color of the cell\n",
    "            text (str): Text to be displayed on the cell\n",
    "            shape (list): Shape of cell in format [h,w]\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: A cell image of shape [h,w,3].\n",
    "        \"\"\"\n",
    "\n",
    "        color_value = int(np.clip(color_value,0,255)) if not np.isnan(color_value) else 127\n",
    "        text = str(text)\n",
    "        cell_shape = (100,100)\n",
    "        (label_width, label_height), baseline = cv2.getTextSize(text, self.font, self.fontScale, self.lineType)\n",
    "        label_patch = np.ones((cell_shape[0], cell_shape[1], 3), np.uint8)*color_value\n",
    "        \n",
    "        textX = int((cell_shape[1] - label_width) / 2)\n",
    "        textY = int((cell_shape[0] + label_height) / 2)\n",
    "        cv2.putText(label_patch, text, (textX, textY), self.font, self.fontScale, self.fontColor, self.lineType)\n",
    "        cell = cv2.resize(label_patch,(shape[1],shape[0]))\n",
    "        return cell\n",
    "        \n",
    "    def generate_confusion_matrix_image(self,image_save_path):\n",
    "        \"\"\"Generate an image representation of the confusion matrix. This could be displayed in the\n",
    "        tensorboard while training or could be used while showcasing model performance. This confusion\n",
    "        matrix also includes the number of samples along with the color coding of cells\n",
    "        \n",
    "        Args:\n",
    "            image_save_path (str): Path to store the confusion matrix image\n",
    "        \n",
    "        Returns:\n",
    "            str: image_save_path, same as what was passed as argument\n",
    "        \"\"\"\n",
    "        confusion_matrix_norm = self.classification_confusion_matrix/self.classification_confusion_matrix.sum(axis=1).reshape(-1,1)\n",
    "        cell_shape = (80,80)\n",
    "        confusion_matrix_image_header = np.hstack([self.create_cell(255,self.num_classes,cell_shape)] + [self.create_cell(150,i,cell_shape) for i in range(self.num_classes)])\n",
    "        confusion_matrix_image = [confusion_matrix_image_header]\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            confusion_matrix_image_row = [self.create_cell(150,i,cell_shape)]\n",
    "            for j in range(self.num_classes):\n",
    "                confusion_matrix_image_cell = self.create_cell(255-confusion_matrix_norm[i][j]*255,int(self.classification_confusion_matrix[i][j]),cell_shape)\n",
    "                confusion_matrix_image_row.append(confusion_matrix_image_cell)\n",
    "            confusion_matrix_image.append(np.hstack(confusion_matrix_image_row))\n",
    "        confusion_matrix_image = np.vstack(confusion_matrix_image)\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(image_save_path)):\n",
    "            os.makedirs(os.path.dirname(image_save_path))\n",
    "\n",
    "        cv2.imwrite(image_save_path,confusion_matrix_image)\n",
    "        print(\"Save confusion matrix image at\",image_save_path)\n",
    "        return image_save_path\n",
    "\n",
    "    def add_sample(self, gt_class, pred_class):\n",
    "        \"\"\"Add a sample to the confusion matrix. A sample is one data point containing\n",
    "        a ground truth and a prediction. This function also check if the ground truth and\n",
    "        prediction exists in the classes or not\n",
    "        \n",
    "        Args:\n",
    "            gt_class (str): Name of the ground truth class\n",
    "            pred_class (str): Name of the predicted class\n",
    "        \"\"\"\n",
    "        assert gt_class in self.classes, \"class {} not found in classes\".format(gt_class)\n",
    "        assert pred_class in self.classes, \"class {} not found in classes\".format(pred_class)\n",
    "\n",
    "        self.classification_confusion_matrix[self.class2int[gt_class]][self.class2int[pred_class]] += 1\n",
    "    \n",
    "    def get_precision_recall_accuracy_support(self, average_mode='none'):\n",
    "        \"\"\"Get performance metrics of current state of the object. This function will return\n",
    "        precision, recall, accuracy and support. By default it will return a list for each of\n",
    "        those of size len(classes) for per class metric. Optionally it can also return average\n",
    "        over all classes\n",
    "        \n",
    "        Args:\n",
    "            average_mode (bool, optional): If this is set to True, average over all classes will be returned\n",
    "            If set to false [default], a list of per class metric will be returned. Defaults to False.\n",
    "        \n",
    "        Returns:\n",
    "            list: list of [precision,recall,accuracy,support]\n",
    "        \"\"\"\n",
    "        # Row wise and column wise sum for calculating precision and recall\n",
    "        hr_sum = np.sum(self.classification_confusion_matrix,axis=1)\n",
    "        vr_sum = np.sum(self.classification_confusion_matrix,axis=0)\n",
    "\n",
    "        # Lists for per class precision, recall, accuracy, support\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        accuracies = []\n",
    "        supports = []\n",
    "\n",
    "        for i,c in enumerate(self.classes):\n",
    "            # tp: True positive is the number that appears on the diagonal\n",
    "\n",
    "            tp = self.classification_confusion_matrix[i][i]\n",
    "\n",
    "            # fp: For a given prediction i, False positive are all the predictions that were not actually i.\n",
    "            fp = vr_sum[i]-tp\n",
    "\n",
    "            # fn: For a ground truth i, False negative is all the ground truths that were not predicted as i.\n",
    "            fn = hr_sum[i]-tp\n",
    "            \n",
    "            if tp == 0:\n",
    "                precision = 0.0\n",
    "                recall = 0.0\n",
    "                accuracy = 0.0\n",
    "            else:\n",
    "                precision = (tp/(tp+fp))\n",
    "                recall = (tp/(tp+fn))\n",
    "                accuracy = tp/(tp+fp+fn)\n",
    "            \n",
    "            support = (tp+fn)\n",
    "\n",
    "            if support==0:\n",
    "                precision = 1.0\n",
    "                recall = 1.0\n",
    "                accuracy = 1.0 \n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            accuracies.append(accuracy)\n",
    "            supports.append(support)\n",
    "\n",
    "        if average_mode == 'weighted':\n",
    "            # compute weighted average of accuracies, precision and recall.\n",
    "            weighted_average_accuracy, weighted_average_precision, weighted_average_recall = 0., 0., 0.\n",
    "            total_instances = sum(supports)\n",
    "            for num_instances, accuracy, precision, recall in zip(supports, accuracies, precisions, recalls):\n",
    "                class_fraction = num_instances/total_instances\n",
    "                weighted_accuracy = class_fraction * accuracy\n",
    "                weighted_precision = class_fraction * precision\n",
    "                weighted_recall = class_fraction * recall\n",
    "                weighted_average_accuracy += weighted_accuracy\n",
    "                weighted_average_precision += weighted_precision\n",
    "                weighted_average_recall += weighted_recall\n",
    "\n",
    "            return weighted_average_precision, weighted_average_recall, weighted_average_accuracy, np.mean(supports)\n",
    "\n",
    "        elif average_mode == 'unweighted':\n",
    "            return np.mean(precisions), np.mean(recalls), np.mean(accuracies), np.mean(supports)\n",
    "\n",
    "        return np.array(precisions), np.array(recalls), np.array(accuracies), np.array(supports)\n",
    "\n",
    "    def create_confusion_matrix_report(self, csv_path):\n",
    "        \"\"\"Create a CSV report of the confusion matrix. This report will also have per class\n",
    "        accuracy, precision, recall and support.\n",
    "        \n",
    "        Args:\n",
    "            csv_path (str): Path to store the csv report file\n",
    "        \n",
    "        Returns:\n",
    "            str: csv_path, same as passed in parameters\n",
    "        \"\"\"\n",
    "        header = [\"confusion matrix\"] + self.classes + [\"ground truth\",\"precision\", \"recall\", \"accuracy\",\"support\",\"prediction\",\"num predictions\"]\n",
    "        rows = [header]\n",
    "\n",
    "        precisions, recalls, accuracies, supports = self.get_precision_recall_accuracy_support()\n",
    "\n",
    "        for i,c in enumerate(self.classes):\n",
    "            row = [c]+[int(x) for x in self.classification_confusion_matrix[i]]\n",
    "            precision = precisions[i]\n",
    "            recall = recalls[i]\n",
    "            accuracy = accuracies[i]\n",
    "            support = supports[i]\n",
    "\n",
    "            row.append(c)\n",
    "            row.append(precision)\n",
    "            row.append(recall)\n",
    "            row.append(accuracy)\n",
    "            row.append(support)\n",
    "\n",
    "            pred_index = np.argmax(self.classification_confusion_matrix[i])\n",
    "            row.append(self.classes[pred_index])\n",
    "            row.append(self.classification_confusion_matrix[i][pred_index])\n",
    "        #     print(len(row))\n",
    "            rows.append(row)\n",
    "        \n",
    "        footer = [\"\"] + [\"\"]*self.num_classes + [\"Average\",np.mean(precisions), np.mean(recalls), np.mean(accuracies),\"\",\"\",\"\"]\n",
    "        rows.append(footer)\n",
    "        \n",
    "        if not os.path.exists(os.path.dirname(csv_path)):\n",
    "            os.makedirs(os.path.dirname(csv_path))\n",
    "\n",
    "        with open(csv_path, 'w') as csvFile:\n",
    "            writer = csv.writer(csvFile)\n",
    "            writer.writerows(rows)\n",
    "        print(\"Saved classification report at\",csv_path)\n",
    "\n",
    "        return csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING_1/quant_model\"\n",
    "dataPath = \"/opt/infilect/dev/dataset/resize\"\n",
    "jsnFilePath = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING_1/quant_resnet50_1\"\n",
    "savePath = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZED_AWARE_TRAINING_1/VIZ1\"\n",
    "with open(f\"{jsnFilePath}/idx2Label.json\", 'r') as jF: idx2Label = json.load(jF)\n",
    "with open(f\"{jsnFilePath}/label2Idx.json\", 'r') as jF: label2Idx = json.load(jF)\n",
    "idx2Label = {int(k):v for k, v in idx2Label.items()}\n",
    "\n",
    "# with open(\"/opt/infilect/dev/storage2/shyam/Data/KH_USA/DPD/splitData/ModelLogs/SigMax/Run_1/khusa-brand-dpd-sigmax-1/tag_to_label.json\", 'r') as jF: label2Idx = json.load(jF)\n",
    "# idx2Label = {int(v): k for k, v in label2Idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03234b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLabels = list(idx2Label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06005289",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLabels, len(finalLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testAug = DataAugmentor(0., 0., 0., 0., 0., 0., 0., 0., normImage=True)\n",
    "# testSet = SimpleLoader(F\"{dataPath}/test\", augObject=testAug, \n",
    "#                validLbls=set(), cacheImgs=True, label2Idx=None, idx2Label=None)\n",
    "test_set = SimpleLoader(F\"{dataPath}/test\", augObject=testAug, \n",
    "               validLbls=set(), cacheImgs=False, label2Idx=label2Idx.copy(), idx2Label=idx2Label.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b578f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_set, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = F\"{modelPath}/model_int8_3.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4726b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myModel = BasicModel(\"resnet50\", len(idx2Label)).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_torchscript_model(model_filepath, device = \"cpu\"):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2acf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel1 = load_torchscript_model(model_filepath = modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561c37b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa467a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineParams = torch.load(modelPath, map_location=\"cpu\")\n",
    "# modelParams = engineParams[\"modelParams\"]\n",
    "# myModel.load_state_dict(engineParams[\"modelParams\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301733c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, criterion=None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73692f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x = evaluate_model(model = myModel1, test_loader = test_set, device = \"cpu\", criterion=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70808e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be03a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validClassIdx = set([v for k, v in label2Idx.items() if k in finalLabels])\n",
    "validClassIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa209d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(savePath, exist_ok = True)\n",
    "gV_N, pV_N = onEvalOld(myModel1, test_set, idx2Label, f\"{savePath}/test_eval_quant_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "gV_N = np.asarray(gV_N)\n",
    "pV_N = {k:np.asarray(pV_N[k]) for k in pV_N.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pV_N[50] = pV_N[50].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2958e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pV_N.keys(): print(k, (pV_N[k] == gV_N).sum() / len(gV_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd506292",
   "metadata": {},
   "outputs": [],
   "source": [
    "newIdxLabelMap = deepcopy(idx2Label)\n",
    "# newIdxLabelMap[-1] = \"notImportant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "isLegacy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3296a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isLegacy: micMetrics, macMatrics = getMetricJson_Legacy(gV_N, pV_N, newIdxLabelMap)\n",
    "else: micMetrics, macMatrics = getMetricJson(gV_N, pV_N, newIdxLabelMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c147ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "micMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "macMatrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754504be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pV_N.keys():\n",
    "    metClass = ClassificationMetrics(\"demo\", list(newIdxLabelMap.values()))\n",
    "    if isLegacy: \n",
    "        for g, p in zip(gV_N, pV_N[k]): metClass.add_sample(newIdxLabelMap[g], newIdxLabelMap[p])\n",
    "    else: \n",
    "        for g, p in zip(gV_N, pV_N[k]): metClass.add_sample(newIdxLabelMap[g+1], newIdxLabelMap[p+1])\n",
    "    avgPrec, avgRcall, avgAcc = [np.mean(i) for i in metClass.get_precision_recall_accuracy_support()[:3]]\n",
    "    print(\" Threshhold :\", k, \"Precision\", avgPrec, \" Recall\", avgRcall, \" Accuracy\", avgAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397faa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metClass = ClassificationMetrics(\"demo\", list(newIdxLabelMap.values()))\n",
    "for g, p in zip(gV_N, pV_N[50]): \n",
    "    if isLegacy: metClass.add_sample(newIdxLabelMap[g], newIdxLabelMap[p])\n",
    "    else: metClass.add_sample(newIdxLabelMap[g+1], newIdxLabelMap[p+1])\n",
    "metClass.create_confusion_matrix_report(F\"{savePath}/quant_resnet50_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61040380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf4c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e79e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee4ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6569b7bf",
   "metadata": {},
   "source": [
    "# Trace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model2(model, model_filepath, device):\n",
    "    model_skeleton = torch.load(model_filepath, device)\n",
    "    print(model_skeleton)\n",
    "\n",
    "    model.load_state_dict(model_skeleton[\"modelParams\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a017670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = quantized_model\n",
    "model_filepath = \"/opt/infilect/dev/repos/image_classification_quant/models/QUANTIZATION/quant_model_2/checkPoints/Epoch_2/engineParams.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "quant_model = load_model2(model, model_filepath, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961d806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def trace_model(modelArch, example, pathToSave:str, name:str):\n",
    "    \n",
    "    modelArch.to(\"cuda\")\n",
    "    \n",
    "    modelArch.eval()\n",
    "    \n",
    "    model = torch.jit.trace(modelArch, torch.randn(example))\n",
    "    \n",
    "    model.save(os.path.join(pathToSave, f\"{name}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de8ef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelArch = model_int8\n",
    "example = (1, 3, 1125, 1500)\n",
    "pathToSave = \"/opt/infilect/dev/repos/image_classification_quant/models/traced\"\n",
    "name = \"quant_int8_resnet50\"\n",
    "trace_model(modelArch, example, pathToSave, name)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b5d8251",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6e7197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainTestPlot(plot, train_accu, test_accu, train_losses, test_losses, model_name):\n",
    "\n",
    "    if plot:\n",
    "        Path('plot/').mkdir(parents=True, exist_ok=True)\n",
    "        plot1 = plt.figure(1)\n",
    "        plt.plot(train_accu, '-o')\n",
    "        plt.plot(test_accu, '-o')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.legend(['Train','Test'])\n",
    "        plt.title('Train vs Test Accuracy')            \n",
    "        plt.savefig('plot/'+model_name+'_train_test_acc.png')\n",
    "\n",
    "        plot2 = plt.figure(2)\n",
    "        plt.plot(train_losses,'-o')\n",
    "        plt.plot(test_losses,'-o')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('losses')\n",
    "        plt.legend(['Train','Test'])\n",
    "        plt.title('Train vs Test Losses')\n",
    "        plt.savefig('plot/'+model_name+'_train_test_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTestPlot(plot = True, train_accu = train_acc, test_accu = val_acc, train_losses = train_loss, test_losses = val_loss, model_name = \"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(trainloader)\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(trainloader):\n",
    "        data_, target_ = data_[0].to(device), target_[0.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data_ = quant(data_)\n",
    "        outputs = model(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        quantizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Iteration [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_t, target_t in (testloader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(testloader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\n')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(model.state_dict(), f'/opt/infilect/dev/repos/image_classification/models/resnet_{epoch}.pth')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    \n",
    "    lrSched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cffb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import *\n",
    "\n",
    "def create_model(num_classes=10):\n",
    "\n",
    "    # The number of channels in ResNet18 is divisible by 8.\n",
    "    # This is required for fast GEMM integer matrix multiplication.\n",
    "    # model = torchvision.models.resnet18(pretrained=False)\n",
    "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
    "\n",
    "    # We would use the pretrained ResNet18 as a feature extractor.\n",
    "    # for param in model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "\n",
    "    # Modify the last FC layer\n",
    "    # num_features = model.fc.in_features\n",
    "    # model.fc = nn.Linear(num_features, 10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = create_model(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddc041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfff49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module_name, module in model1.named_children():\n",
    "    print(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fa920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model1 = torch.ao.quantization.fuse_modules_qat(model1, [[\"conv1\", \"bn1\", \"relu\"]], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c490104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "yHAT = [torch.tensor([[-0.1099,  0.0676],\n",
    "        [ 0.0213, -0.1472]], device='cuda:0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd28ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yHAT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee829f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a8cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optimization",
   "language": "python",
   "name": "optimize"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
